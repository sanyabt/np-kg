{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dental-demonstration",
   "metadata": {},
   "source": [
    "## Code to generate TSV from NP-KG gpickle graph\n",
    "\n",
    "1. Load merged pickle graph.\n",
    "2. Create TSV with URIs.\n",
    "3. Create TSV with CURIEs.\n",
    "4. Create node labels with CURIEs.\n",
    "\n",
    "See weighting experiments for TSV files with weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affecting-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment and run to install any required modules from np-kg/requirements.txt\n",
    "# import sys\n",
    "# !{sys.executable} -m pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "grand-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import networkx as nx\n",
    "import json\n",
    "import urllib\n",
    "import traceback\n",
    "from itertools import islice\n",
    "from rdflib import Graph, URIRef, BNode, Namespace, Literal\n",
    "from rdflib.namespace import RDF, OWL\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "convertible-oregon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hashlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "enabling-textbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "elect-viewer",
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_PATH = '../resources/knowledge_graphs/'\n",
    "NodeLabelsFile = KG_PATH + 'nodeLabels_v2.0.0.pickle'\n",
    "KG_NAME_MERGED = 'NP-KG_v2.0.0.gpickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "distinct-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(NodeLabelsFile, 'rb') as filep:\n",
    "    nodeLabels = pickle.load(filep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "qualified-speaking",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090470"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##N (v1.0.1) = 757826\n",
    "len(nodeLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "faced-november",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_graph_stats(kg):\n",
    "    nodes = nx.number_of_nodes(kg)\n",
    "    edges = nx.number_of_edges(kg)\n",
    "    self_loops = nx.number_of_selfloops(kg)\n",
    "\n",
    "    print('There are {} nodes, {} edges, and {} self-loop(s)'.format(nodes, edges, self_loops))\n",
    "    # get degree information\n",
    "    avg_degree = float(edges) / nodes\n",
    "    print('The Average Degree is {}'.format(avg_degree))\n",
    "    \n",
    "    print('Nodes with highest degree:')\n",
    "    n_deg = sorted([(str(x[0]), x[1]) for x in  kg.degree], key=lambda x: x[1], reverse=1)[:6]\n",
    "\n",
    "    for x in n_deg:\n",
    "        print('Label: {}'.format(nodeLabels[x[0]]))\n",
    "        print('{} (degree={})'.format(x[0], x[1]))\n",
    "    # get network density\n",
    "    density = nx.density(kg)\n",
    "\n",
    "    print('The density of the graph is: {}'.format(density))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "assumed-kuwait",
   "metadata": {},
   "outputs": [],
   "source": [
    "##READ MERGED GRAPH\n",
    "with open(KG_PATH+KG_NAME_MERGED, 'rb') as filep:\n",
    "    nx_graph = pickle.load(filep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comprehensive-warner",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_graph_stats(nx_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "solid-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "npkgdict = {\n",
    "    'subject': [],\n",
    "    'predicate': [],\n",
    "    'object': []\n",
    "}\n",
    "nodelist = []\n",
    "missing_nodes = []\n",
    "relation_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "solar-classic",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTFILE = KG_PATH + 'NP-KG_v2.0.0.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "middle-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed edges:  100000\n",
      "Saved edges:  100000\n",
      "Completed edges:  200000\n",
      "Saved edges:  200000\n",
      "Completed edges:  300000\n",
      "Saved edges:  300000\n",
      "Completed edges:  400000\n",
      "Saved edges:  400000\n",
      "Completed edges:  500000\n",
      "Saved edges:  500000\n",
      "Completed edges:  600000\n",
      "Saved edges:  600000\n",
      "Completed edges:  700000\n",
      "Saved edges:  700000\n",
      "Completed edges:  800000\n",
      "Saved edges:  800000\n",
      "Completed edges:  900000\n",
      "Saved edges:  900000\n",
      "Completed edges:  1000000\n",
      "Saved edges:  1000000\n",
      "Completed edges:  1100000\n",
      "Saved edges:  1100000\n",
      "Completed edges:  1200000\n",
      "Saved edges:  1200000\n",
      "Completed edges:  1300000\n",
      "Saved edges:  1300000\n",
      "Completed edges:  1400000\n",
      "Saved edges:  1400000\n",
      "Completed edges:  1500000\n",
      "Saved edges:  1500000\n",
      "Completed edges:  1600000\n",
      "Saved edges:  1600000\n",
      "Completed edges:  1700000\n",
      "Saved edges:  1700000\n",
      "Completed edges:  1800000\n",
      "Saved edges:  1800000\n",
      "Completed edges:  1900000\n",
      "Saved edges:  1900000\n",
      "Completed edges:  2000000\n",
      "Saved edges:  2000000\n",
      "Completed edges:  2100000\n",
      "Saved edges:  2100000\n",
      "Completed edges:  2200000\n",
      "Saved edges:  2200000\n",
      "Completed edges:  2300000\n",
      "Saved edges:  2300000\n",
      "Completed edges:  2400000\n",
      "Saved edges:  2400000\n",
      "Completed edges:  2500000\n",
      "Saved edges:  2500000\n",
      "Completed edges:  2600000\n",
      "Saved edges:  2600000\n",
      "Completed edges:  2700000\n",
      "Saved edges:  2700000\n",
      "Completed edges:  2800000\n",
      "Saved edges:  2800000\n",
      "Completed edges:  2900000\n",
      "Saved edges:  2900000\n",
      "Completed edges:  3000000\n",
      "Saved edges:  3000000\n",
      "Completed edges:  3100000\n",
      "Saved edges:  3100000\n",
      "Completed edges:  3200000\n",
      "Saved edges:  3200000\n",
      "Completed edges:  3300000\n",
      "Saved edges:  3300000\n",
      "Completed edges:  3400000\n",
      "Saved edges:  3400000\n",
      "Completed edges:  3500000\n",
      "Saved edges:  3500000\n",
      "Completed edges:  3600000\n",
      "Saved edges:  3600000\n",
      "Completed edges:  3700000\n",
      "Saved edges:  3700000\n",
      "Completed edges:  3800000\n",
      "Saved edges:  3800000\n",
      "Completed edges:  3900000\n",
      "Saved edges:  3900000\n",
      "Completed edges:  4000000\n",
      "Saved edges:  4000000\n",
      "Completed edges:  4100000\n",
      "Saved edges:  4100000\n",
      "Completed edges:  4200000\n",
      "Saved edges:  4200000\n",
      "Completed edges:  4300000\n",
      "Saved edges:  4300000\n",
      "Completed edges:  4400000\n",
      "Saved edges:  4400000\n",
      "Completed edges:  4500000\n",
      "Saved edges:  4500000\n",
      "Completed edges:  4600000\n",
      "Saved edges:  4600000\n",
      "Completed edges:  4700000\n",
      "Saved edges:  4700000\n",
      "Completed edges:  4800000\n",
      "Saved edges:  4800000\n",
      "Completed edges:  4900000\n",
      "Saved edges:  4900000\n",
      "Completed edges:  5000000\n",
      "Saved edges:  5000000\n",
      "Completed edges:  5100000\n",
      "Saved edges:  5100000\n",
      "Completed edges:  5200000\n",
      "Saved edges:  5200000\n",
      "Completed edges:  5300000\n",
      "Saved edges:  5300000\n",
      "Completed edges:  5400000\n",
      "Saved edges:  5400000\n",
      "Completed edges:  5500000\n",
      "Saved edges:  5500000\n",
      "Completed edges:  5600000\n",
      "Saved edges:  5600000\n",
      "Completed edges:  5700000\n",
      "Saved edges:  5700000\n",
      "Completed edges:  5800000\n",
      "Saved edges:  5800000\n",
      "Completed edges:  5900000\n",
      "Saved edges:  5900000\n",
      "Completed edges:  6000000\n",
      "Saved edges:  6000000\n",
      "Completed edges:  6100000\n",
      "Saved edges:  6100000\n",
      "Completed edges:  6200000\n",
      "Saved edges:  6200000\n",
      "Completed edges:  6300000\n",
      "Saved edges:  6300000\n",
      "Completed edges:  6400000\n",
      "Saved edges:  6400000\n",
      "Completed edges:  6500000\n",
      "Saved edges:  6500000\n",
      "Completed edges:  6600000\n",
      "Saved edges:  6600000\n",
      "Completed edges:  6700000\n",
      "Saved edges:  6700000\n",
      "Completed edges:  6800000\n",
      "Saved edges:  6800000\n",
      "Completed edges:  6900000\n",
      "Saved edges:  6900000\n",
      "Completed edges:  7000000\n",
      "Saved edges:  7000000\n",
      "Completed edges:  7100000\n",
      "Saved edges:  7100000\n",
      "Completed edges:  7200000\n",
      "Saved edges:  7200000\n",
      "Completed edges:  7300000\n",
      "Saved edges:  7300000\n",
      "Completed edges:  7400000\n",
      "Saved edges:  7400000\n",
      "Completed edges:  7500000\n",
      "Saved edges:  7500000\n",
      "Completed edges:  7600000\n",
      "Saved edges:  7600000\n",
      "Completed edges:  7700000\n",
      "Saved edges:  7700000\n",
      "Completed edges:  7800000\n",
      "Saved edges:  7800000\n",
      "Completed edges:  7900000\n",
      "Saved edges:  7900000\n",
      "Completed edges:  7920893\n",
      "Saved edges:  7920893\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for edge in nx_graph.edges():\n",
    "    edgelist = list(nx_graph.get_edge_data(edge[0], edge[1]))\n",
    "    if edgelist:\n",
    "        subj = str(edge[0])\n",
    "        obj = str(edge[1])\n",
    "        if subj not in nodelist:\n",
    "            nodelist.append(subj)\n",
    "            if subj not in nodeLabels:\n",
    "                missing_nodes.append(subj)\n",
    "        if obj not in nodelist:\n",
    "            nodelist.append(obj)\n",
    "            if obj not in nodeLabels:\n",
    "                missing_nodes.append(obj)\n",
    "        for item in edgelist:\n",
    "            npkgdict['subject'].append(subj)\n",
    "            npkgdict['object'].append(obj)\n",
    "            npkgdict['predicate'].append(str(item))\n",
    "            if str(item) not in relation_list:\n",
    "                relation_list.append(str(item))\n",
    "                if str(item) not in nodeLabels:\n",
    "                    missing_nodes.append(str(item))\n",
    "    i = i+1\n",
    "    if i%100000 == 0:\n",
    "        print('Completed edges: ', i)\n",
    "        df = pd.DataFrame.from_dict(npkgdict)\n",
    "        df = df.drop_duplicates(ignore_index=True)\n",
    "        df.to_csv(OUTFILE, sep='\\t', mode='a', index=False, header=False)\n",
    "        npkgdict['subject'] = []\n",
    "        npkgdict['predicate'] = []\n",
    "        npkgdict['object'] = []\n",
    "        print('Saved edges: ', i)\n",
    "print('Completed edges: ', i)\n",
    "df = pd.DataFrame.from_dict(npkgdict)\n",
    "df = df.drop_duplicates(ignore_index=True)\n",
    "df.to_csv(OUTFILE, sep='\\t', mode='a', index=False, header=False)\n",
    "print('Saved edges: ', i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fossil-issue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090172"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(nodelist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "occupied-vermont",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "355"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(relation_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dc9b336",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "measured-spectacular",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(missing_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "boolean-binding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22567 22567 22567\n"
     ]
    }
   ],
   "source": [
    "print(len(npkgdict['subject']), len(npkgdict['predicate']), len(npkgdict['object']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "short-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/NPKG_nodelist.txt', 'w') as fileo:\n",
    "    for item in nodelist:\n",
    "        fileo.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "happy-livestock",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/NPKG_relationlist.txt', 'w') as fileo2:\n",
    "    for item in relation_list:\n",
    "        fileo2.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "piano-studio",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/NPKG_missing_nodelabels.txt', 'w') as fileo3:\n",
    "    for item in missing_nodes:\n",
    "        fileo3.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "seeing-gravity",
   "metadata": {},
   "source": [
    "### Save TSV with only CURIES (solve issue #5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "demonstrated-bowling",
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_PATH = '../resources/knowledge_graphs/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "violent-newton",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFILE = KG_PATH + 'NP-KG_v2.0.0.tsv'\n",
    "OUTFILE = KG_PATH + 'NP-KG-CURIE-only-v2.0.0.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "northern-chest",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "theoretical-guinea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1090172"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##find all node prefixes\n",
    "with open('../resources/NPKG_nodelist.txt', 'r') as filei:\n",
    "    nodes = filei.readlines()\n",
    "len(nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "prerequisite-encoding",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "534466\n",
      "51\n"
     ]
    }
   ],
   "source": [
    "prefixlist = []\n",
    "curielist = []\n",
    "for node in nodes:\n",
    "    if 'http://purl.obolibrary.org/obo/' in node:\n",
    "        onto = node.strip().replace('http://purl.obolibrary.org/obo/', '')\n",
    "        curie = onto.split('_')[0]\n",
    "        if curie not in curielist:\n",
    "            curielist.append(curie)\n",
    "    else:\n",
    "        prefixlist.append(node.strip())\n",
    "print(len(prefixlist))\n",
    "print(len(curielist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "breeding-satin",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UBERON',\n",
       " 'SO',\n",
       " 'PR',\n",
       " 'GO',\n",
       " 'NCBITaxon',\n",
       " 'CHEBI',\n",
       " 'PW',\n",
       " 'GNO',\n",
       " 'MOD',\n",
       " 'CLO',\n",
       " 'CL',\n",
       " 'HP',\n",
       " 'MONDO',\n",
       " 'OAE',\n",
       " 'CARO',\n",
       " 'PATO',\n",
       " 'BFO',\n",
       " 'DOID',\n",
       " 'FOODON',\n",
       " 'DIDEO',\n",
       " 'DRON',\n",
       " 'UO',\n",
       " 'INO',\n",
       " 'PDRO/PDRO.owl#PDRO',\n",
       " 'IDO',\n",
       " 'APOLLO',\n",
       " 'FMA',\n",
       " 'ERO',\n",
       " 'GAZ',\n",
       " 'CHMO',\n",
       " 'MPATH',\n",
       " 'NBO',\n",
       " 'ENVO',\n",
       " 'CHR',\n",
       " 'PO',\n",
       " 'EnsemblBacteria#',\n",
       " 'MFOMD',\n",
       " 'ECTO',\n",
       " 'HsapDv',\n",
       " 'NCIT',\n",
       " 'MF',\n",
       " 'ExO',\n",
       " 'OGMS',\n",
       " 'MOP',\n",
       " 'VO',\n",
       " 'Ensembl#',\n",
       " 'PCO',\n",
       " 'OGG',\n",
       " 'STATO',\n",
       " 'MAXO',\n",
       " 'UPHENO']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "curielist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "particular-highland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37319"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixlist2 = []\n",
    "for prefix in prefixlist:\n",
    "    if 'napdi' in prefix or 'https://reactome.org/content/detail/' in prefix \\\n",
    "    or 'http://www.ncbi.nlm.nih.gov/gene/' in prefix or 'https://uswest.ensembl.org/Homo_sapiens/Transcript/Summary?' \\\n",
    "    in prefix or 'http://www.ebi.ac.uk/cellline#' in prefix or 'http://www.ebi.ac.uk/efo/' in prefix or \\\n",
    "    'https://www.ncbi.nlm.nih.gov/snp/' in prefix or 'http://ihtsdo.org/snomedct/' in prefix \\\n",
    "    or 'https://bar.utoronto.ca/' in prefix or 'http://flybase.org/' in prefix \\\n",
    "    or 'http://dictybase.org/gene/' in prefix or 'http://rgd.mcw.edu/rgdweb/report/gene/' in prefix\\\n",
    "    or 'http://zfin.org/action/marker/view/' in prefix or 'http://birdgenenames.org/cgnc/' in prefix:\n",
    "        continue\n",
    "    else:\n",
    "        prefixlist2.append(prefix)\n",
    "len(prefixlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "339f46c6-d000-49fd-be05-0d3c291a854f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixlist2 = []\n",
    "for prefix in prefixlist:\n",
    "    if 'napdi' in prefix or 'https://reactome.org/content/detail/' in prefix \\\n",
    "    or 'http://www.ncbi.nlm.nih.gov/gene/' in prefix or 'https://uswest.ensembl.org/Homo_sapiens/Transcript/Summary?' \\\n",
    "    in prefix or 'http://www.ebi.ac.uk/cellline#' in prefix or 'http://www.ebi.ac.uk/efo/' in prefix or \\\n",
    "    'https://www.ncbi.nlm.nih.gov/snp/' in prefix or 'http://ihtsdo.org/snomedct/' in prefix \\\n",
    "    or 'http://dictybase.org/gene/' in prefix or 'https://bar.utoronto.ca/' in prefix\\\n",
    "    or 'http://rgd.mcw.edu/rgdweb/report/gene/' in prefix \\\n",
    "    or 'http://flybase.org/' in prefix or 'http://zfin.org/action/marker/view/' in prefix \\\n",
    "    or 'http://birdgenenames.org/cgnc/' in prefix or 'wormbase' in prefix or 'informatics' in prefix\\\n",
    "    or 'yeastgenome' in prefix or 'ecogene' in prefix or 'pombase' in prefix\\\n",
    "    or 'ensembl' in prefix:\n",
    "        continue\n",
    "    else:\n",
    "        prefixlist2.append(prefix)\n",
    "len(prefixlist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3c56e39-07fe-4ddd-9dde-d311036f5b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['http://www.geneontology.org/formats/oboInOwl#Synonym',\n",
       " 'http://www.geneontology.org/formats/oboInOwl#Definition',\n",
       " 'http://www.geneontology.org/formats/oboInOwl#SynonymType',\n",
       " 'http://www.geneontology.org/formats/oboInOwl#DbXref',\n",
       " 'http://www.geneontology.org/formats/oboInOwl#Subset',\n",
       " 'https://ghr.nlm.nih.gov/condition/saddan',\n",
       " 'http://www.genenames.org/cgi-bin/gene_symbol_report?hgnc_id=55921',\n",
       " 'https://rarediseases.info.nih.gov/diseases/9644/multicentric-castleman-disease']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prefixlist2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "personalized-nation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_curie(rel):\n",
    "    newrel = rel\n",
    "    if 'uberon' in rel:\n",
    "        newrel = 'uberon:'+rel.split('#')[1]\n",
    "    elif 'rdf-schema' in rel:\n",
    "        newrel = 'rdfs:'+rel.split('#')[1]\n",
    "    elif 'rdf-syntax' in rel:\n",
    "        newrel = 'rdf:'+rel.split('#')[1]\n",
    "    elif 'ro.owl' in rel:\n",
    "        newrel = 'ro:'+rel.split('#')[1]\n",
    "    else:\n",
    "        temp = rel.split('/')[-1]\n",
    "        if '#' in temp:\n",
    "            temp = temp.split('#')\n",
    "            newrel = temp[0]+':'+temp[1]\n",
    "        else:\n",
    "            newrel = temp.replace('_', ':').lower()\n",
    "    return newrel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "selective-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node_curie(node):\n",
    "    nodecurie = node\n",
    "    if 'http://purl.obolibrary.org/obo/OBO_' in node:\n",
    "        tempnode = node.replace('http://purl.obolibrary.org/obo/OBO_', '')\n",
    "        nodecurie = tempnode.replace('_',':').lower()\n",
    "    elif 'napdi' in node:\n",
    "        nodecurie = node.split('/')[-1]\n",
    "    elif 'reactome' in node:\n",
    "        nodecurie = 'reactome:'+node.split('/')[-1]\n",
    "    elif 'http://www.ncbi.nlm.nih.gov/gene/' in node:\n",
    "        nodecurie = 'ncbigene:'+node.split('/')[-1]\n",
    "    elif 'https://uswest.ensembl.org/Homo_sapiens/Transcript/Summary?' in node:\n",
    "        nodecurie = node.replace('https://uswest.ensembl.org/Homo_sapiens/Transcript/Summary?t=', 'ensembl:')\n",
    "    elif 'ensembl' in node:\n",
    "        nodecurie = 'ensembl:'+node.split('/')[-1]\n",
    "    elif 'http://www.ebi.ac.uk/efo/' in node:\n",
    "        tempnode = node.split('/')[-1]\n",
    "        nodecurie = tempnode.replace('_',':').lower()\n",
    "    elif 'http://ihtsdo.org/snomedct/' in node or 'http://purl.bioontology.org/ontology/SNOMEDCT/' in node:\n",
    "        nodecurie = 'snomedct:'+node.split('/')[-1]\n",
    "    elif 'https://www.ncbi.nlm.nih.gov/snp/' in node:\n",
    "        nodecurie = 'dbsnp:'+node.split('/')[-1]\n",
    "    elif 'http://www.w3.org/2002/07/' in node:\n",
    "        tempnode = node.split('/')[-1]\n",
    "        nodecurie = 'owl:'+tempnode.split('#')[-1]\n",
    "    elif 'hgnc_id' in node:\n",
    "        nodecurie = 'hgnc:'+node.split('=')[-1]\n",
    "    elif 'http://sig.uw.edu/fma' in node:\n",
    "        tempnode = node.split('/')[-1]\n",
    "        nodecurie = 'fma:'+tempnode.split('#')[-1]\n",
    "    elif 'http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl' in node:\n",
    "        tempnode = node.replace('http://ncicb.nci.nih.gov/xml/owl/EVS/Thesaurus.owl#', '')\n",
    "        nodecurie = 'ncit:'+tempnode\n",
    "    elif 'https://bar.utoronto.ca/' in node:\n",
    "        nodecurie = 'bar:'+node.split('=')[-1]\n",
    "    elif 'http://flybase.org/' in node:\n",
    "        nodecurie = 'flybase:'+node.split('/')[-1]\n",
    "    elif 'http://dictybase.org/gene/' in node:\n",
    "        nodecurie = 'dictyBase:'+node.split('/')[-1]\n",
    "    elif 'http://rgd.mcw.edu/rgdweb/report/gene/' in node:\n",
    "        nodecurie = 'rgd:'+node.split('/')[-1]\n",
    "    elif 'http://zfin.org/action/marker/view/' in node:\n",
    "        nodecurie = 'zfin:'+node.split('/')[-1]\n",
    "    elif 'http://birdgenenames.org/cgnc/' in node:\n",
    "        nodecurie = 'birdgenenames:'+node.split('=')[-1]\n",
    "    elif 'informatics' in node:\n",
    "        tempnode = node.split('/')[-1]\n",
    "        nodecurie = 'mgi:'+tempnode.split(':')[-1]\n",
    "    elif 'wormbase' in node:\n",
    "        nodecurie = 'wormbase:'+node.split('/')[-1]\n",
    "    elif 'yeastgenome' in node:\n",
    "        nodecurie = 'yeastgenome:'+node.split('/')[-1]\n",
    "    elif 'ecogene' in node:\n",
    "        nodecurie = 'ecogene:'+node.split('/')[-1]\n",
    "    elif 'pombase' in node:\n",
    "        nodecurie = 'pombase:'+node.split('/')[-1]\n",
    "    elif 'https://ghr.nlm.nih.gov/condition/' in node:\n",
    "        nodecurie = 'ghr:'+node.split('/')[-1]\n",
    "    elif 'https://rarediseases.info.nih.gov/diseases/' in node:\n",
    "        nodecurie = 'rare:'+node.split('/')[-1]\n",
    "    elif 'PDRO/PDRO.owl#PDRO' in node:\n",
    "        temp = node.split('#')[-1]\n",
    "        nodecurie = 'pdro:'+temp.split('_')[-1]\n",
    "    else:\n",
    "        tempnode = node.replace('http://purl.obolibrary.org/obo/', '')\n",
    "        nodecurie = tempnode.replace('_',':').lower()\n",
    "    return nodecurie"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "17d6d46e",
   "metadata": {},
   "source": [
    "### Save to TSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "grand-quebec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed edges:  100000\n",
      "Completed edges:  200000\n",
      "Completed edges:  300000\n",
      "Completed edges:  400000\n",
      "Completed edges:  500000\n",
      "Completed edges:  600000\n",
      "Completed edges:  700000\n",
      "Completed edges:  800000\n",
      "Completed edges:  900000\n",
      "Completed edges:  1000000\n",
      "Completed edges:  1100000\n",
      "Completed edges:  1200000\n",
      "Completed edges:  1300000\n",
      "Completed edges:  1400000\n",
      "Completed edges:  1500000\n",
      "Completed edges:  1600000\n",
      "Completed edges:  1700000\n",
      "Completed edges:  1800000\n",
      "Completed edges:  1900000\n",
      "Completed edges:  2000000\n",
      "Completed edges:  2100000\n",
      "Completed edges:  2200000\n",
      "Completed edges:  2300000\n",
      "Completed edges:  2400000\n",
      "Completed edges:  2500000\n",
      "Completed edges:  2600000\n",
      "Completed edges:  2700000\n",
      "Completed edges:  2800000\n",
      "Completed edges:  2900000\n",
      "Completed edges:  3000000\n",
      "Completed edges:  3100000\n",
      "Completed edges:  3200000\n",
      "Completed edges:  3300000\n",
      "Completed edges:  3400000\n",
      "Completed edges:  3500000\n",
      "Completed edges:  3600000\n",
      "Completed edges:  3700000\n",
      "Completed edges:  3800000\n",
      "Completed edges:  3900000\n",
      "Completed edges:  4000000\n",
      "Completed edges:  4100000\n",
      "Completed edges:  4200000\n",
      "Completed edges:  4300000\n",
      "Completed edges:  4400000\n",
      "Completed edges:  4500000\n",
      "Completed edges:  4600000\n",
      "Completed edges:  4700000\n",
      "Completed edges:  4800000\n",
      "Completed edges:  4900000\n",
      "Completed edges:  5000000\n",
      "Completed edges:  5100000\n",
      "Completed edges:  5200000\n",
      "Completed edges:  5300000\n",
      "Completed edges:  5400000\n",
      "Completed edges:  5500000\n",
      "Completed edges:  5600000\n",
      "Completed edges:  5700000\n",
      "Completed edges:  5800000\n",
      "Completed edges:  5900000\n",
      "Completed edges:  6000000\n",
      "Completed edges:  6100000\n",
      "Completed edges:  6200000\n",
      "Completed edges:  6300000\n",
      "Completed edges:  6400000\n",
      "Completed edges:  6500000\n",
      "Completed edges:  6600000\n",
      "Completed edges:  6700000\n",
      "Completed edges:  6800000\n",
      "Completed edges:  6900000\n",
      "Completed edges:  7000000\n",
      "Completed edges:  7100000\n",
      "Completed edges:  7200000\n",
      "Completed edges:  7300000\n",
      "Completed edges:  7400000\n",
      "Completed edges:  7500000\n",
      "Completed edges:  7600000\n",
      "Completed edges:  7700000\n",
      "Completed edges:  7800000\n",
      "Completed edges:  7900000\n"
     ]
    }
   ],
   "source": [
    "with open(INFILE, 'r') as fin, open(OUTFILE, 'w') as fout:\n",
    "    freader = csv.reader(fin, delimiter='\\t')\n",
    "    fwriter = csv.writer(fout, delimiter='\\t')\n",
    "    fwriter.writerow(['source', 'relation', 'target'])\n",
    "    idx = 1\n",
    "    for row in freader:\n",
    "        try:\n",
    "            npkg_subject = row[0]\n",
    "            npkg_relation = row[1]\n",
    "            npkg_object = row[2]\n",
    "            rel_curie = relation_curie(npkg_relation)\n",
    "            subject_curie = get_node_curie(npkg_subject)\n",
    "            object_curie = get_node_curie(npkg_object)\n",
    "            fwriter.writerow([subject_curie, rel_curie, object_curie])\n",
    "        except Exception as e:\n",
    "            print('Error: ', e)\n",
    "            print(idx)\n",
    "            print(row)\n",
    "        idx+=1\n",
    "        if idx%100000 == 0:\n",
    "            print('Completed edges: ', idx)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4400f08e",
   "metadata": {},
   "source": [
    "## Create new nodelabels with curies\n",
    "\n",
    "#### Also create URI to CURIE map and vice versa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "falling-behavior",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODEINFILE = KG_PATH + 'nodeLabels_v2.0.0.tsv'\n",
    "NODEOUTFILE = KG_PATH + 'nodeLabels_CURIE_v2.0.0.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "extra-partnership",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed nodes:  10000\n",
      "Completed nodes:  20000\n",
      "Completed nodes:  30000\n",
      "Completed nodes:  40000\n",
      "Completed nodes:  50000\n",
      "Completed nodes:  60000\n",
      "Completed nodes:  70000\n",
      "Completed nodes:  80000\n",
      "Completed nodes:  90000\n",
      "Completed nodes:  100000\n",
      "Completed nodes:  110000\n",
      "Completed nodes:  120000\n",
      "Completed nodes:  130000\n",
      "Completed nodes:  140000\n",
      "Completed nodes:  150000\n",
      "Completed nodes:  160000\n",
      "Completed nodes:  170000\n",
      "Completed nodes:  180000\n",
      "Completed nodes:  190000\n",
      "Completed nodes:  200000\n",
      "Completed nodes:  210000\n",
      "Completed nodes:  220000\n",
      "Completed nodes:  230000\n",
      "Completed nodes:  240000\n",
      "Completed nodes:  250000\n",
      "Completed nodes:  260000\n",
      "Completed nodes:  270000\n",
      "Completed nodes:  280000\n",
      "Completed nodes:  290000\n",
      "Completed nodes:  300000\n",
      "Completed nodes:  310000\n",
      "Completed nodes:  320000\n",
      "Completed nodes:  330000\n",
      "Completed nodes:  340000\n",
      "Completed nodes:  350000\n",
      "Completed nodes:  360000\n",
      "Completed nodes:  370000\n",
      "Completed nodes:  380000\n",
      "Completed nodes:  390000\n",
      "Completed nodes:  400000\n",
      "Completed nodes:  410000\n",
      "Completed nodes:  420000\n",
      "Completed nodes:  430000\n",
      "Completed nodes:  440000\n",
      "Completed nodes:  450000\n",
      "Completed nodes:  460000\n",
      "Completed nodes:  470000\n",
      "Completed nodes:  480000\n",
      "Completed nodes:  490000\n",
      "Completed nodes:  500000\n",
      "Completed nodes:  510000\n",
      "Completed nodes:  520000\n",
      "Completed nodes:  530000\n",
      "Completed nodes:  540000\n",
      "Completed nodes:  550000\n",
      "Completed nodes:  560000\n",
      "Completed nodes:  570000\n",
      "Completed nodes:  580000\n",
      "Completed nodes:  590000\n",
      "Completed nodes:  600000\n",
      "Completed nodes:  610000\n",
      "Completed nodes:  620000\n",
      "Completed nodes:  630000\n",
      "Completed nodes:  640000\n",
      "Completed nodes:  650000\n",
      "Completed nodes:  660000\n",
      "Completed nodes:  670000\n",
      "Completed nodes:  680000\n",
      "Completed nodes:  690000\n",
      "Completed nodes:  700000\n",
      "Completed nodes:  710000\n",
      "Completed nodes:  720000\n",
      "Completed nodes:  730000\n",
      "Completed nodes:  740000\n",
      "Completed nodes:  750000\n",
      "Completed nodes:  760000\n",
      "Completed nodes:  770000\n",
      "Completed nodes:  780000\n",
      "Completed nodes:  790000\n",
      "Completed nodes:  800000\n",
      "Completed nodes:  810000\n",
      "Completed nodes:  820000\n",
      "Completed nodes:  830000\n",
      "Completed nodes:  840000\n",
      "Completed nodes:  850000\n",
      "Completed nodes:  860000\n",
      "Completed nodes:  870000\n",
      "Completed nodes:  880000\n",
      "Completed nodes:  890000\n",
      "Completed nodes:  900000\n",
      "Completed nodes:  910000\n",
      "Completed nodes:  920000\n",
      "Completed nodes:  930000\n",
      "Completed nodes:  940000\n",
      "Completed nodes:  950000\n",
      "Completed nodes:  960000\n",
      "Completed nodes:  970000\n",
      "Completed nodes:  980000\n",
      "Completed nodes:  990000\n",
      "Completed nodes:  1000000\n",
      "Completed nodes:  1010000\n",
      "Completed nodes:  1020000\n",
      "Completed nodes:  1030000\n",
      "Completed nodes:  1040000\n",
      "Completed nodes:  1050000\n",
      "Completed nodes:  1060000\n",
      "Completed nodes:  1070000\n",
      "Completed nodes:  1080000\n",
      "Completed nodes:  1090000\n"
     ]
    }
   ],
   "source": [
    "##node labels with CURIEs\n",
    "\n",
    "uri_to_curie_dict = {}\n",
    "curie_to_uri_dict = {}\n",
    "\n",
    "with open(NODEINFILE, 'r') as nodein, open(NODEOUTFILE, 'w') as nodeout:\n",
    "    freader = csv.reader(nodein, delimiter='\\t')\n",
    "    fwriter = csv.writer(nodeout, delimiter='\\t')\n",
    "    fwriter.writerow(['source', 'entity_label'])\n",
    "    next(freader)\n",
    "    idx = 1\n",
    "    for row in freader:\n",
    "        try:\n",
    "            npkg_node = row[0]\n",
    "            npkg_label = row[1]\n",
    "            nodecurie = get_node_curie(npkg_node)\n",
    "            fwriter.writerow([nodecurie, npkg_label])\n",
    "            uri_to_curie_dict[npkg_node] = nodecurie\n",
    "            curie_to_uri_dict[nodecurie] = npkg_node\n",
    "        except Exception as e:\n",
    "            print('Error: ', e)\n",
    "            print(idx)\n",
    "            print(row)\n",
    "        idx+=1\n",
    "        if idx%10000 == 0:\n",
    "            print('Completed nodes: ', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e8dd433a",
   "metadata": {},
   "outputs": [],
   "source": [
    "##save dictionaries as TSV files\n",
    "with open(KG_PATH+'uri_to_curie_map.tsv', 'w') as fileo:\n",
    "    for key, value in uri_to_curie_dict.items():\n",
    "        fileo.write(key+'\\t'+value+'\\n')\n",
    "\n",
    "with open(KG_PATH+'curie_to_uri_map.tsv', 'w') as fileo:\n",
    "    for key, value in curie_to_uri_dict.items():\n",
    "        fileo.write(key+'\\t'+value+'\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-television",
   "metadata": {},
   "source": [
    "### Convert relation CURIEs to labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "analyzed-contrary",
   "metadata": {},
   "outputs": [],
   "source": [
    "KG_PATH = '../resources/knowledge_graphs/'\n",
    "INFILE = KG_PATH + 'NP-KG-CURIE-only-v2.0.0.tsv'\n",
    "OUTFILE = KG_PATH + 'NP-KG-CURIE-with-relations-v2.0.0.tsv'\n",
    "nodeLabelsFile = KG_PATH + 'nodeLabels_CURIE_v2.0.0.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "tired-speaking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "acting-alberta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1090470 entries, 0 to 1090469\n",
      "Data columns (total 2 columns):\n",
      " #   Column        Non-Null Count    Dtype \n",
      "---  ------        --------------    ----- \n",
      " 0   source        1090470 non-null  object\n",
      " 1   entity_label  1089225 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 16.6+ MB\n"
     ]
    }
   ],
   "source": [
    "nodedf = pd.read_csv(nodeLabelsFile, sep='\\t')\n",
    "nodedf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "extended-receipt",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>entity_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cl:0000594</td>\n",
       "      <td>skeletal muscle satellite cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ensembl:ENST00000456565</td>\n",
       "      <td>DARS1-206</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dbsnp:rs750861887</td>\n",
       "      <td>NM_000256.3(MYBPC3):c.1944C&gt;T (p.His648=)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>pr:q8wu43</td>\n",
       "      <td>uncharacterized protein C2orf15 (human)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pr:q9m9h3</td>\n",
       "      <td>embryogenesis-like protein (Arabidopsis thaliana)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    source                                       entity_label\n",
       "0               cl:0000594                     skeletal muscle satellite cell\n",
       "1  ensembl:ENST00000456565                                          DARS1-206\n",
       "2        dbsnp:rs750861887          NM_000256.3(MYBPC3):c.1944C>T (p.His648=)\n",
       "3                pr:q8wu43            uncharacterized protein C2orf15 (human)\n",
       "4                pr:q9m9h3  embryogenesis-like protein (Arabidopsis thaliana)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodedf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "sorted-remainder",
   "metadata": {},
   "outputs": [],
   "source": [
    "##need to fix none issue in new version (N=17k approx errors in relations propagated from PheKnowLator)\n",
    "relations_dict = {\n",
    "    'rdfs:subClassOf': 'rdfs:subClassOf',\n",
    "    'rdf:type': 'rdf:type',\n",
    "    'sio:000420': 'has expression'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "identical-observer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "yellow-latest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed edges:  100000\n",
      "Completed edges:  200000\n",
      "Completed edges:  300000\n",
      "Completed edges:  400000\n",
      "Completed edges:  500000\n",
      "Completed edges:  600000\n",
      "Completed edges:  700000\n",
      "Completed edges:  800000\n",
      "Completed edges:  900000\n",
      "Completed edges:  1000000\n",
      "Completed edges:  1100000\n",
      "Completed edges:  1200000\n",
      "Completed edges:  1300000\n",
      "Completed edges:  1400000\n",
      "Completed edges:  1500000\n",
      "Completed edges:  1600000\n",
      "Completed edges:  1700000\n",
      "Completed edges:  1800000\n",
      "Completed edges:  1900000\n",
      "Completed edges:  2000000\n",
      "Completed edges:  2100000\n",
      "Completed edges:  2200000\n",
      "Completed edges:  2300000\n",
      "Completed edges:  2400000\n",
      "Completed edges:  2500000\n",
      "Completed edges:  2600000\n",
      "Completed edges:  2700000\n",
      "Completed edges:  2800000\n",
      "Completed edges:  2900000\n",
      "Completed edges:  3000000\n",
      "Completed edges:  3100000\n",
      "Completed edges:  3200000\n",
      "Completed edges:  3300000\n",
      "Completed edges:  3400000\n",
      "Completed edges:  3500000\n",
      "Completed edges:  3600000\n",
      "Completed edges:  3700000\n",
      "Completed edges:  3800000\n",
      "Completed edges:  3900000\n",
      "Completed edges:  4000000\n",
      "Completed edges:  4100000\n",
      "Completed edges:  4200000\n",
      "Completed edges:  4300000\n",
      "Completed edges:  4400000\n",
      "Completed edges:  4500000\n",
      "Completed edges:  4600000\n",
      "Completed edges:  4700000\n",
      "Completed edges:  4800000\n",
      "Completed edges:  4900000\n",
      "Completed edges:  5000000\n",
      "Completed edges:  5100000\n",
      "Completed edges:  5200000\n",
      "Completed edges:  5300000\n",
      "Completed edges:  5400000\n",
      "Completed edges:  5500000\n",
      "Completed edges:  5600000\n",
      "Completed edges:  5700000\n",
      "Completed edges:  5800000\n",
      "Completed edges:  5900000\n",
      "Completed edges:  6000000\n",
      "Completed edges:  6100000\n",
      "Completed edges:  6200000\n",
      "Completed edges:  6300000\n",
      "Completed edges:  6400000\n",
      "Completed edges:  6500000\n",
      "Completed edges:  6600000\n",
      "Completed edges:  6700000\n",
      "Completed edges:  6800000\n",
      "Completed edges:  6900000\n",
      "Completed edges:  7000000\n",
      "Completed edges:  7100000\n",
      "Completed edges:  7200000\n",
      "Completed edges:  7300000\n",
      "Completed edges:  7400000\n",
      "Completed edges:  7500000\n",
      "Completed edges:  7600000\n",
      "Completed edges:  7700000\n",
      "Completed edges:  7800000\n",
      "Completed edges:  7900000\n"
     ]
    }
   ],
   "source": [
    "with open(INFILE, 'r') as fin, open(OUTFILE, 'w') as fout:\n",
    "    freader = csv.reader(fin, delimiter='\\t')\n",
    "    fwriter = csv.writer(fout, delimiter='\\t')\n",
    "    fwriter.writerow(['source', 'relation', 'target'])\n",
    "    idx = 1\n",
    "    next(freader)\n",
    "    for row in freader:\n",
    "        try:\n",
    "            npkg_subject = row[0]\n",
    "            npkg_relation = row[1]\n",
    "            npkg_object = row[2]\n",
    "            rel_label = npkg_relation\n",
    "            if npkg_relation in relations_dict:\n",
    "                rel_label = relations_dict[npkg_relation]\n",
    "            else:\n",
    "                rel_row = nodedf.loc[nodedf['source'] == npkg_relation]\n",
    "                if not rel_row.empty:\n",
    "                    rel_label = rel_row['entity_label'].values[0]\n",
    "                    if 'entity_type' in rel_label:\n",
    "                        rel_dict = ast.literal_eval(rel_label)\n",
    "                        rel_label = rel_dict['label']\n",
    "                    relations_dict[npkg_relation] = rel_label\n",
    "            fwriter.writerow([npkg_subject, rel_label, npkg_object])\n",
    "        except Exception as e:\n",
    "            print('Error: ', e)\n",
    "            print(idx)\n",
    "            print(row)\n",
    "        idx+=1\n",
    "        if idx%100000 == 0:\n",
    "            print('Completed edges: ', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "turned-connectivity",
   "metadata": {},
   "outputs": [],
   "source": [
    "##write out rows with errors to file\n",
    "with open(OUTFILE, 'a') as f:\n",
    "    fwriter = csv.writer(f, delimiter='\\t')\n",
    "    fwriter.writerow(['envo:00002203', 'envo:has_increased_levels_of', 'chebi:24835'])\n",
    "    fwriter.writerow(['envo:00002202', 'envo:has_increased_levels_of', 'chebi:50860'])\n",
    "    fwriter.writerow(['envo:00002186', 'envo:has_increased_levels_of', 'chebi:24431'])\n",
    "    fwriter.writerow(['envo:01000676', 'envo:has_increased_levels_of', 'chebi:24431'])\n",
    "    fwriter.writerow(['envo:01001040', 'envo:has_increased_levels_of', 'chebi:26710'])\n",
    "    fwriter.writerow(['envo:00002114', 'envo:has_increased_levels_of', 'chebi:24431'])\n",
    "    fwriter.writerow(['envo:00002010', 'envo:has_increased_levels_of', 'chebi:26710'])\n",
    "    fwriter.writerow(['mfomd:0000024', 'mf:manifestationof', 'mfomd:0000004'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4cd6caf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "da0f468a",
   "metadata": {},
   "source": [
    "## Create node type dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31f428ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "curie_to_node_type_dict = {\n",
    "'ensembl': 'sequence',\n",
    "'uberon': 'anatomy',\n",
    "'pr':'protein',\n",
    "'reactome':'pathway',\n",
    "'so':'sequence',\n",
    "'chebi':'chemical',\n",
    "'go':'process',\n",
    "'mondo':'disease',\n",
    "'dbsnp': 'variant',\n",
    "'hp':'phenotype',\n",
    "'ncbigene':'gene',\n",
    "'bar':'sequence',\n",
    "'ncbitaxon':'organism',\n",
    "'clo':'cell_line',\n",
    "'mgi':'other',\n",
    "'cl':'cell',\n",
    "'dideo':'drug_drug_interaction',\n",
    "'rgd':'rat_genome',\n",
    "'flybase':'fly',\n",
    "'pw':'pathway',\n",
    "'oae':'adverse_event',\n",
    "'pato':'trait',\n",
    "'ecogene':'ecoli_gene',\n",
    "'pombase':'yeast_genome',\n",
    "'yeastgenome':'yeast_genome',\n",
    "'mod':'other',\n",
    "'po':'plant',\n",
    "'caro':'other',\n",
    "'dictyBase':'dictyo_genome',\n",
    "'envo':'env',\n",
    "'zfin':'zebrafish',\n",
    "'wormbase':'worm',\n",
    "'efo':'other',\n",
    "'gno':'other',\n",
    "'napdi_srs_imports':'napdi',\n",
    "'birdgenenames':'bird_gene',\n",
    "'mpath':'mouse_pathology',\n",
    "'ensemblbacteria#':'bacteria',\n",
    "'doid':'disease',\n",
    "'ecto':'env',\n",
    "'exo':'other',\n",
    "'foodon':'food',\n",
    "'apollo':'other',\n",
    "'http':'other',\n",
    "'chr':'other',\n",
    "'uo':'other',\n",
    "'nbo':'behavior',\n",
    "'ncit':'ncit',\n",
    "'pdro':'other',\n",
    "'ensembl#':'sequence',\n",
    "'hsapdv':'dev_stage',\n",
    "'mfomd':'other',\n",
    "'gaz':'other',\n",
    "'dron':'drug',\n",
    "'ogg':'other',\n",
    "'ino':'other',\n",
    "'ido':'other',\n",
    "'fma':'other',\n",
    "'vo':'vaccine',\n",
    "'mf':'other',\n",
    "'ero':'other',\n",
    "'ghr':'other',\n",
    "'pco':'other',\n",
    "'ogms':'other',\n",
    "'chmo':'other',\n",
    "'hgnc':'gene',\n",
    "'maxo':'other',\n",
    "'stato':'other',\n",
    "'mop':'other',\n",
    "'upheno':'other',\n",
    "'rare':'other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "320e7409",
   "metadata": {},
   "outputs": [],
   "source": [
    "INFILE = KG_PATH + 'nodeLabels_CURIE_v2.0.0.tsv'\n",
    "OUTFILE = KG_PATH + 'nodeTypes_CURIE_v2.0.0.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c51bdf1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed nodes:  100000\n",
      "Completed nodes:  200000\n",
      "Completed nodes:  300000\n",
      "Completed nodes:  400000\n",
      "Completed nodes:  500000\n",
      "Completed nodes:  600000\n",
      "Completed nodes:  700000\n",
      "Completed nodes:  800000\n",
      "Completed nodes:  900000\n",
      "Completed nodes:  1000000\n"
     ]
    }
   ],
   "source": [
    "with open(INFILE, 'r') as fin, open(OUTFILE, 'w') as fout:\n",
    "    freader = csv.reader(fin, delimiter='\\t')\n",
    "    fwriter = csv.writer(fout, delimiter='\\t')\n",
    "    fwriter.writerow(['curie', 'category'])\n",
    "    idx = 1\n",
    "    next(freader)\n",
    "    for row in freader:\n",
    "        try:\n",
    "            node_curie = row[0]\n",
    "            node_type = node_curie.split(':')[0]\n",
    "            if node_type in curie_to_node_type_dict:\n",
    "                node_type = curie_to_node_type_dict[node_type]\n",
    "            else:\n",
    "                node_type = 'other'\n",
    "            fwriter.writerow([node_curie, node_type])\n",
    "        except Exception as e:\n",
    "            print('Error: ', e)\n",
    "            print(idx)\n",
    "            print(row)\n",
    "        idx+=1\n",
    "        if idx%100000 == 0:\n",
    "            print('Completed nodes: ', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95f6b6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "NODEINFILE = KG_PATH + 'nodeLabels_v2.0.0.tsv'\n",
    "NODEOUTFILE = KG_PATH + 'nodeTypes_v2.0.0.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eeecf738",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load mapping dicts\n",
    "uri_to_curie_dict = {}\n",
    "curie_to_uri_dict = {}\n",
    "with open(KG_PATH+'uri_to_curie_map.tsv', 'r') as file1:\n",
    "    for line in file1:\n",
    "        uri_to_curie_dict[line.split('\\t')[0]] = line.split('\\t')[1].strip()\n",
    "\n",
    "with open(KG_PATH+'curie_to_uri_map.tsv', 'r') as file2:\n",
    "    for line in file2:\n",
    "        curie_to_uri_dict[line.split('\\t')[0]] = line.split('\\t')[1].strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f3f16a8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cl:0000594 http://purl.obolibrary.org/obo/CL_0000594\n"
     ]
    }
   ],
   "source": [
    "for key in curie_to_uri_dict:\n",
    "    print(key, curie_to_uri_dict[key])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "95b4c47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed nodes:  100000\n",
      "Completed nodes:  200000\n",
      "Completed nodes:  300000\n",
      "Completed nodes:  400000\n",
      "Completed nodes:  500000\n",
      "Completed nodes:  600000\n",
      "Completed nodes:  700000\n",
      "Completed nodes:  800000\n",
      "Completed nodes:  900000\n",
      "Completed nodes:  1000000\n"
     ]
    }
   ],
   "source": [
    "with open(NODEINFILE, 'r') as fin, open(NODEOUTFILE, 'w') as fout:\n",
    "    freader = csv.reader(fin, delimiter='\\t')\n",
    "    fwriter = csv.writer(fout, delimiter='\\t')\n",
    "    fwriter.writerow(['uri', 'category'])\n",
    "    idx = 1\n",
    "    next(freader)\n",
    "    for row in freader:\n",
    "        try:\n",
    "            node_uri = row[0]\n",
    "            node_curie = uri_to_curie_dict.get(node_uri, node_uri)\n",
    "            node_type = node_curie.split(':')[0]\n",
    "            if node_type in curie_to_node_type_dict:\n",
    "                node_type = curie_to_node_type_dict[node_type]\n",
    "            else:\n",
    "                node_type = 'other'\n",
    "            fwriter.writerow([node_uri, node_type])\n",
    "        except Exception as e:\n",
    "            print('Error: ', e)\n",
    "            print(idx)\n",
    "            print(row)\n",
    "        idx+=1\n",
    "        if idx%100000 == 0:\n",
    "            print('Completed nodes: ', idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd3d8e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.13 ('sanya_kg')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "41f6dbb4620f1287d918c6d619d0adb09c41576ea2dff392e8096d45e1460f3a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
