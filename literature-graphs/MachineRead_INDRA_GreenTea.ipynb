{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "95926c97-6356-4501-89ac-35918073a44c",
   "metadata": {},
   "source": [
    "## Create literature-based graph for green tea from INDRA/REACH triples\n",
    "\n",
    "### Steps for processing:\n",
    "1. Map subjects, objects, and relations to OBO ontologies.\n",
    "2. Add prefixes for all CURIEs.\n",
    "3. Save triples as NetworkX graph.\n",
    "4. Save triples as ntriples graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5f6837-8220-42fd-a03c-6bf402cbaa5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "leading-least",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgt = pd.read_csv('../resources/predication_files/greentea_all_predicates_INDRA.tsv', sep='\\t')\n",
    "dfgt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "considerable-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-brick",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter columns\n",
    "df = dfgt[['subject_cui', 'subject_name', 'subject_source', 'predicate', 'object_source',\n",
    "       'object_cui', 'object_name', 'subj_reach_grounding', 'obj_reach_grounding', 'pmid', \n",
    "           'pub_year', 'belief', 'sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-nerve",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add columns for OBO mappings\n",
    "df['predicate_obo'] = None\n",
    "df['subject_obo'] = None\n",
    "df['object_obo'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "grateful-baghdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "latest-virus",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Mapping file for UMLS to GO and HPO\n",
    "go_hpo_map = pd.read_csv('cui_to_ontology_maps/go_hpo_map.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "whole-durham",
   "metadata": {},
   "outputs": [],
   "source": [
    "go_hpo_mapping_dict = {}\n",
    "for i in range(len(go_hpo_map.index)):\n",
    "    cui = go_hpo_map.at[i,'cui']\n",
    "    if cui not in go_hpo_mapping_dict:\n",
    "        go_hpo_mapping_dict[cui] = []\n",
    "    code = go_hpo_map.at[i, 'code']\n",
    "    code = code.replace(':', '_')\n",
    "    go_hpo_mapping_dict[cui].append(code)\n",
    "print(len(go_hpo_mapping_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dangerous-group",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "certified-indicator",
   "metadata": {},
   "outputs": [],
   "source": [
    "reach_grounding_dict = {}\n",
    "for i in range(len(df.index)):\n",
    "    sub_cui = df.at[i, 'subject_cui']\n",
    "    reach_grounding_dict[sub_cui] = []\n",
    "    obj_cui = df.at[i, 'object_cui']\n",
    "    if obj_cui not in reach_grounding_dict:\n",
    "        reach_grounding_dict[obj_cui] = []\n",
    "    sub_ground = df.at[i, 'subj_reach_grounding']\n",
    "    obj_ground = df.at[i, 'obj_reach_grounding']\n",
    "    if sub_ground != np.nan:\n",
    "        if 'CHEBI' in sub_ground or 'GO' in sub_ground:\n",
    "            subject_map = sub_ground.split(\"'\")[-2]\n",
    "            subject_map = subject_map.replace(':', '_')\n",
    "            reach_grounding_dict[sub_cui].append(subject_map)\n",
    "        elif 'UP' in sub_ground:\n",
    "            subject_map = sub_ground.split(\"'\")[-2]\n",
    "            subject_map = 'PR_' + subject_map\n",
    "            reach_grounding_dict[sub_cui].append(subject_map)\n",
    "    if obj_ground != np.nan:\n",
    "        if 'CHEBI' in obj_ground or 'GO' in obj_ground:\n",
    "            object_map = obj_ground.split(\"'\")[-2]\n",
    "            object_map = object_map.replace(':', '_')\n",
    "            reach_grounding_dict[obj_cui].append(object_map)\n",
    "        elif 'UP' in obj_ground:\n",
    "            object_map = obj_ground.split(\"'\")[-2]\n",
    "            object_map = 'PR_' + object_map\n",
    "            reach_grounding_dict[obj_cui].append(object_map)\n",
    "print(len(reach_grounding_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-still",
   "metadata": {},
   "outputs": [],
   "source": [
    "predMapD = {\n",
    "    'regulateactivity':'RO_0011002',\n",
    "    'regulateamount':'RO_0011003',\n",
    "    'phosphorylation':'RO_0002447',\n",
    "    'dephosphorylation':'GO_0006470',\n",
    "    'ubiquitination':'RO_0002480',\n",
    "    'deubiquitination':'GO_0016579',\n",
    "    'sumoylation':'RO_0002436',\n",
    "    'desumoylation':'RO_0002436',\n",
    "    'hydroxylation':'GO_0018126',\n",
    "    'dehydroxylation':'RO_0002436',\n",
    "    'acetylation':'GO_0006473',\n",
    "    'deacetylation':'GO_0006476',\n",
    "    'glycosylation':'GO_0006486',\n",
    "    'deglycosylation':'GO_0006517',\n",
    "    'farnesylation':'RO_0002436',\n",
    "    'defarnesylation':'RO_0002436',\n",
    "    'geranylgeranylation':'RO_0002436',\n",
    "    'degeranylgeranylation':'RO_0002436',\n",
    "    'palmitoylation':'RO_0002436',\n",
    "    'depalmitoylation':'RO_0002436',\n",
    "    'myristoylation':'RO_0002436',\n",
    "    'demyristoylation':'RO_0002436',\n",
    "    'ribosylation':'RO_0002436',\n",
    "    'deribosylation':'RO_0002436',\n",
    "    'methylation':'GO_0006479',\n",
    "    'demethylation':'GO_0006482',\n",
    "    'activation':'RO_0002448',\n",
    "    'inhibition':'RO_0002449',\n",
    "    'increaseamount':'RO_0011009',\n",
    "    'decreaseamount':'RO_0011010'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if reach_grounding has multiple values, currently only first one is taken\n",
    "def get_obo_mapping(row, col):\n",
    "    if col == 'subject':\n",
    "        cui = row['subject_cui']\n",
    "    elif col == 'object':\n",
    "        cui = row['object_cui']\n",
    "    else:\n",
    "        print('specify is subject or object mapping required')\n",
    "        exit(0)\n",
    "    if cui in go_hpo_mapping_dict:\n",
    "        if len(go_hpo_mapping_dict):\n",
    "            return go_hpo_mapping_dict[cui][0]\n",
    "    if cui in reach_grounding_dict:\n",
    "        if len(reach_grounding_dict[cui]):\n",
    "            return reach_grounding_dict[cui][0]\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "digital-grenada",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_mapping(row):\n",
    "    rel = row['predicate'].lower()\n",
    "    if rel in predMapD:\n",
    "        return predMapD[rel]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "built-stick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicate_obo'] = df.apply(relation_mapping, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tested-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject_obo'] = df.apply(get_obo_mapping, axis=1, col='subject')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-efficiency",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['object_obo'] = df.apply(get_obo_mapping, axis=1, col='object')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caroline-average",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04197a8e-a0d2-47f1-be5d-28faa182e748",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load ontorunner mappings and map CUIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96097918-e9f7-47f6-a04d-609dd0ae80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cui_to_ontology_maps/CUItoOBO_20220505.pickle', 'rb') as filep:\n",
    "    onto_dict = pickle.load(filep)\n",
    "len(onto_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "practical-swiss",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ontorunner mappings and add to df\n",
    "def get_obo_onto_mapping(row, col):\n",
    "    if col == 'subject':\n",
    "        cui = row['subject_cui']\n",
    "        mapping = row['subject_obo']\n",
    "    elif col == 'object':\n",
    "        cui = row['object_cui']\n",
    "        mapping = row['object_obo']\n",
    "    else:\n",
    "        print('specify if subject or object mapping required')\n",
    "        exit(0)\n",
    "    if mapping == '':\n",
    "        if cui in onto_dict:\n",
    "            return onto_dict[cui]\n",
    "    else:\n",
    "        return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chemical-trick",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject_obo'] = df.apply(get_obo_onto_mapping, axis=1, col='subject')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "weekly-welsh",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['object_obo'] = df.apply(get_obo_onto_mapping, axis=1, col='object')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(row, col):\n",
    "    obo_prefix = 'http://purl.obolibrary.org/obo/'\n",
    "    if col == 'predicate':\n",
    "        predicate_obo = row['predicate_obo']\n",
    "        return obo_prefix+predicate_obo\n",
    "    elif col == 'subject':\n",
    "        subject_obo = row['subject_obo']\n",
    "        if isinstance(subject_obo, list) and subject_obo:\n",
    "            subject_obo = subject_obo[0]\n",
    "        if subject_obo == None:\n",
    "            return ''\n",
    "        subject_obo = subject_obo.replace(']', '')\n",
    "        subject_obo = subject_obo.replace('[', '')\n",
    "        subject_obo = subject_obo.replace(')', '')\n",
    "        subject_obo = subject_obo.replace('(', '')\n",
    "        if 'http' not in subject_obo:\n",
    "            return obo_prefix+subject_obo\n",
    "        else:\n",
    "            return subject_obo\n",
    "    elif col == 'object':\n",
    "        object_obo = row['object_obo']\n",
    "        if isinstance(object_obo, list) and object_obo:\n",
    "            object_obo = object_obo[0]\n",
    "        if object_obo == None:\n",
    "            return ''\n",
    "        object_obo = object_obo.replace(']', '')\n",
    "        object_obo = object_obo.replace('[', '')\n",
    "        object_obo = object_obo.replace(')', '')\n",
    "        object_obo = object_obo.replace('(', '')\n",
    "        if 'http' not in object_obo:\n",
    "            return obo_prefix+object_obo\n",
    "        else:\n",
    "            return object_obo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "confused-forty",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add OBO identifiers to the OBO mappings (where not present) - see df\n",
    "#drop rows with no mappings\n",
    "df['subject_obo'] = df.apply(add_prefix, axis=1, col='subject')\n",
    "df['object_obo'] = df.apply(add_prefix, axis=1, col='object')\n",
    "df['predicate_obo'] = df.apply(add_prefix, axis=1, col='predicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "framed-asian",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fix napdi identifiers\n",
    "for i in range(len(df.index)):\n",
    "    subj = df.at[i, 'subject_obo']\n",
    "    obj = df.at[i, 'object_obo']\n",
    "    if 'napdi' in subj:\n",
    "        subjnew = subj.replace('http://purl.obolibrary.org/obo/', 'http://napdi.org/')\n",
    "        df.at[i, 'subject_obo'] = subjnew\n",
    "    if 'napdi' in obj:\n",
    "        objnew = obj.replace('http://purl.obolibrary.org/obo/', 'http://napdi.org/')\n",
    "        df.at[i, 'object_obo'] = objnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027823f8-8794-4fc0-9c8e-34237b6934a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "obo_prefix = 'http://purl.obolibrary.org/obo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "social-photographer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all rows with blank obo mappings and only prefix rows\n",
    "df_new = df[df['subject_obo'] != '']\n",
    "df_new = df_new[df_new['subject_obo'] != obo_prefix]\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "above-compilation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new['object_obo'] != '']\n",
    "df_new = df_new[df_new['object_obo'] != obo_prefix]\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "photographic-cargo",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop_duplicates()\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "effective-eligibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suspected-gabriel",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('../resources/predication_files/greentea_all_predicates_INDRA_processed.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beginning-desperate",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create networkx graph from triples\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import networkx as nx  # type: ignore\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from collections import Counter  # type: ignore\n",
    "from more_itertools import unique_everseen  # type: ignore\n",
    "from rdflib import BNode, Graph, Literal, Namespace, URIRef  # type: ignore\n",
    "from rdflib.namespace import OWL, RDF, RDFS  # type: ignore\n",
    "from rdflib.plugins.serializers.nt import _quoteLiteral  # type: ignore\n",
    "import subprocess\n",
    "\n",
    "from tqdm import tqdm  # type: ignore\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "# set-up environment variables\n",
    "obo = Namespace('http://purl.obolibrary.org/obo/')\n",
    "oboinowl = Namespace('http://www.geneontology.org/formats/oboInOwl#')\n",
    "schema = Namespace('http://www.w3.org/2001/XMLSchema#')\n",
    "napdi = Namespace('http://napdi.org/napdi_srs_imports:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "relevant-pearl",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = df_new[['subject_obo', 'predicate_obo', 'object_obo']]\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promising-sydney",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres.to_csv('../resources/predication_files/greentea_all_predicates_INDRA_processed_triples.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "northern-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rdflib graph from dataframe triples and serialize as ntriples file\n",
    "graph  = Graph()\n",
    "pred_label = URIRef(\"http://www.w3.org/2000/01/rdf-schema#label\")\n",
    "for i in range(len(df_new.index)):\n",
    "    subj = df_new.at[i, 'subject_obo']\n",
    "    obj = df_new.at[i, 'object_obo']\n",
    "    pred = df_new.at[i, 'predicate_obo']\n",
    "    subj_node = URIRef(subj)\n",
    "    obj_node = URIRef(obj)\n",
    "    predicate = URIRef(pred)\n",
    "    subj_name = df_new.at[i, 'subject_name']\n",
    "    obj_name = df_new.at[i, 'object_name']\n",
    "    graph.add((subj_node, predicate, obj_node))\n",
    "    graph.add((subj_node, pred_label, Literal(subj_name)))\n",
    "    graph.add((obj_node, pred_label, Literal(obj_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "another-choice",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.serialize('output_graphs/machineread_greentea_INDRA.nt', format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupational-forum",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n3(node: Union[URIRef, BNode, Literal]) -> str:\n",
    "    \"\"\"Method takes an RDFLib node of type BNode, URIRef, or Literal and serializes it to meet the RDF 1.1 NTriples\n",
    "    format.\n",
    "    Src: https://github.com/RDFLib/rdflib/blob/c11f7b503b50b7c3cdeec0f36261fa09b0615380/rdflib/plugins/serializers/nt.py\n",
    "    Args:\n",
    "        node: An RDFLib\n",
    "    Returns:\n",
    "        serialized_node: A string containing the serialized\n",
    "    \"\"\"\n",
    "    if isinstance(node, Literal): serialized_node = \"%s\" % _quoteLiteral(node)\n",
    "    else: serialized_node = \"%s\" % node.n3()\n",
    "    return serialized_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "actual-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,p,o in tqdm(graph):\n",
    "    x = str(s)\n",
    "    y = str(p)\n",
    "    z = str(o)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "classified-cradle",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert rdflib graph to multidigraph - code borrowed from PheKnowLator: kg_utils.py\n",
    "#use the pred key to also create a dictionary with metadata about the edge - \n",
    "#pub_year, pmid, source graph, belief\n",
    "nx_mdg = nx.MultiDiGraph()\n",
    "for s, p, o in tqdm(graph):\n",
    "    #do not save label predicate to gpickle\n",
    "    subj = str(s)\n",
    "    obj = str(o)\n",
    "    pred = str(p)\n",
    "    if pred == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "        continue\n",
    "    pred_key = hashlib.md5('{}{}{}'.format(n3(s), n3(p), n3(o)).encode()).hexdigest()\n",
    "    \n",
    "    pmid = str(df_new.loc[(df_new['subject_obo'] == subj) & (df_new['object_obo'] == obj)  & \n",
    "                   (df_new['predicate_obo'] == pred)]['pmid'].values[0])\n",
    "    timestamp = str(df_new.loc[(df_new['subject_obo'] == subj) & (df_new['object_obo'] == obj)  & \n",
    "                               (df_new['predicate_obo'] == pred)]['pub_year'].values[0])\n",
    "    belief_score = df_new.loc[(df_new['subject_obo'] == subj) & (df_new['object_obo'] == obj)  & \n",
    "                               (df_new['predicate_obo'] == pred)]['belief'].values[0]\n",
    "    nx_mdg.add_node(s, key=n3(s))\n",
    "    nx_mdg.add_node(o, key=n3(o))\n",
    "    nx_mdg.add_edge(s, o, **{'key': p, 'predicate_key': pred_key, 'weight':0.0,\n",
    "                             'pmid': pmid, 'timestamp': timestamp, 'source_graph': 'machine_read',\n",
    "                            'belief': belief_score})\n",
    "nx.write_gpickle(nx_mdg, \"output_graphs/machineread_greentea_INDRA.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bottom-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save node labels as dictionary\n",
    "#key: URI, value is label\n",
    "label_dict = {}\n",
    "for i in range(len(df_new.index)):\n",
    "    subj = str(df_new.at[i, 'subject_obo'])\n",
    "    obj = str(df_new.at[i, 'object_obo'])\n",
    "    pred = str(df_new.at[i, 'predicate_obo'])\n",
    "    if subj not in label_dict:\n",
    "        label_dict[subj] = {}\n",
    "        label_dict[subj]['entity_type'] = 'NODES'\n",
    "        label_dict[subj]['label'] = df_new.at[i, 'subject_name']\n",
    "        label_dict[subj]['cui'] = df_new.at[i, 'subject_cui']\n",
    "    if obj not in label_dict:\n",
    "        label_dict[obj] = {}\n",
    "        label_dict[obj]['entity_type'] = 'NODES'\n",
    "        label_dict[obj]['label'] = df_new.at[i, 'object_name']\n",
    "        label_dict[obj]['cui'] = df_new.at[i, 'object_cui']\n",
    "    if pred not in label_dict:\n",
    "        label_dict[pred] = {}\n",
    "        label_dict[pred]['entity_type'] = 'RELATIONS'\n",
    "        label_dict[pred]['label'] = df_new.at[i, 'predicate']\n",
    "len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "international-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('output_graphs/machineread_greentea_INDRA_NodeLabels.pickle', 'wb') as file_p:\n",
    "    pickle.dump(label_dict, file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desirable-click",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = pd.DataFrame.from_dict(label_dict, orient='index')\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "veterinary-arkansas",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = dfmap.reset_index()\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "liquid-effects",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = dfmap.rename(columns={\"index\":\"entity_uri\"})\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "environmental-artist",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap.to_csv('output_graphs/machineread_greentea_INDRA_NodeLabels.tsv', index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
