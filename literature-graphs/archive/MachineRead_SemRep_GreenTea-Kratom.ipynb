{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create literature-based graph for green tea and kratom from SemRep output\n",
    "\n",
    "### Steps for processing:\n",
    "1. Combine all SemRep output files.\n",
    "2. Fix source sentences with errors.\n",
    "3. Extract publication year from date of triple.\n",
    "4. Map subjects, objects and relations to OBO ontologies.\n",
    "5. Save triples as NetworkX graph.\n",
    "6. Save triples as ntriples file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "files = os.listdir('../resources/predication_files/semrep/')\n",
    "#read all files in semrep_data\n",
    "files[0][-3:]\n",
    "df = pd.DataFrame(columns=['index', 'pmid', 'subject_cui', 'subject_type', 'relation', 'object_cui', 'object_type', 'year', 'sentence'])\n",
    "for file in files:\n",
    "    if file[-3:] == 'tsv':\n",
    "        print('Loading file: ', file)\n",
    "        df_temp = pd.read_csv('../resources/predication_files/semrep/'+file, sep='\\t')\n",
    "        print(df_temp.info())\n",
    "        df = pd.concat([df, df_temp], ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates(ignore_index=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use regular expression to fix year as format is not consistent\n",
    "for i in range(len(df.index)):\n",
    "    pub_date = df.at[i, 'year']\n",
    "    x = re.findall(r'\\d+', pub_date)\n",
    "    if x:\n",
    "        df.at[i, 'year'] = x[0]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_sent = df['sentence'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(source_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##fix source sentence\n",
    "last = len(source_sent)-1\n",
    "sentences = []\n",
    "count = 0\n",
    "for sent in source_sent:\n",
    "    sent = sent.strip()\n",
    "    flag = 0\n",
    "    if sent == '' or '|||' in sent:\n",
    "        for i in range(count, -1, -1):\n",
    "            if source_sent[i].strip() == '' or '|||' in source_sent[i].strip():\n",
    "                continue\n",
    "            else:\n",
    "                sentences.append(source_sent[i].strip())\n",
    "                flag = 1\n",
    "                break\n",
    "        if flag == 0:\n",
    "            sentences.append(sent.strip())\n",
    "    else:\n",
    "        sentences.append(sent.strip())\n",
    "    count += 1\n",
    "            \n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.Series(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['source_text'] = sentences\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['sentence', 'index'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##filter SemRep output to only keep these predicates/relations\n",
    "preds = ['affects',\n",
    "'associated_with',\n",
    "'augments',\n",
    "'causes',\n",
    "'coexists_with',\n",
    "'complicates',\n",
    "'disrupts',\n",
    "'inhibits',\n",
    "'interacts_with',\n",
    "'part_of',\n",
    "'precedes',\n",
    "'predisposes',\n",
    "'prevents',\n",
    "'produces',\n",
    "'stimulates',\n",
    "'treats']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicate'] = df['relation'].str.lower()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['relation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = df[df['predicate'].isin(preds)]\n",
    "dfn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn['predicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn['subject_map'] = None\n",
    "dfn['object_map'] = None\n",
    "dfn['predicate_obo'] = None\n",
    "dfn['subject_obo'] = None\n",
    "dfn['object_obo'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add relation ontology mapping\n",
    "predMapSemRep = {\n",
    "'affects': 'RO_0002596',\n",
    "'associated_with': 'RO_0002610',\n",
    "'augments': 'RO_0002598',\n",
    "'causes': 'RO_0002566',\n",
    "'coexists_with': 'RO_0002490',\n",
    "'complicates': 'RO_0003309',\n",
    "'disrupts': 'RO_0002212',\n",
    "'inhibits': 'RO_0002449',\n",
    "'interacts_with': 'RO_0002434',\n",
    "'part_of': 'BFO_0000050',\n",
    "'precedes': 'BFO_0000063',\n",
    "'predisposes': 'RO_0003302',\n",
    "'prevents': 'RO_0002599',\n",
    "'produces': 'RO_0003000',\n",
    "'stimulates': 'RO_0002213',\n",
    "'treats': 'RO_0002606'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_mapping(row):\n",
    "    rel = row['predicate'].lower()\n",
    "    if rel in predMapSemRep:\n",
    "        return predMapSemRep[rel]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn['predicate_obo'] = dfn.apply(relation_mapping, axis=1)\n",
    "dfn.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn = dfn.reset_index(drop=True)\n",
    "dfn.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter semantic types here and then start mapping\n",
    "excluded_semtype = ['acty','bhvr','evnt','gora','mcha','ocac', #Occupational Activity\n",
    "'clas',\n",
    "'cnce',\n",
    "'ftcn',\n",
    "'grpa',\n",
    "'idcn',\n",
    "'inpr',\n",
    "'lang',\n",
    "'qlco',\n",
    "'qnco',\n",
    "'rnlw',\n",
    "'spco',\n",
    "'tmco',\n",
    "'enty',\n",
    "'mnob',\n",
    "'phob',\n",
    "'bmod',\n",
    "'ocdi',\n",
    "'hcro',\n",
    "'orgt',\n",
    "'pros',\n",
    "'shro',\n",
    "'eehu',\n",
    "'hcpp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn1 = dfn[~dfn['subject_type'].isin(excluded_semtype)]\n",
    "dfn1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn2 = dfn1[~dfn1['object_type'].isin(excluded_semtype)]\n",
    "dfn2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##exclude all concepts that occur in SemMedDB GENERIC.CONCEPT table\n",
    "#Get CSV file - https://lhncbc.nlm.nih.gov/ii/tools/SemRep_SemMedDB_SKR/SemMedDB_download.html -- doesn't work\n",
    "#download from https://github.com/kilicogluh/lbd-covid/tree/master/preprocessing/conf\n",
    "semmed = pd.read_csv('cui_to_ontology_maps/semmedVER43_2020_R_GENERIC_CONCEPT.csv', header=None)\n",
    "semmed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semmed = semmed.rename(columns={1: 'CUI', 2: 'concept_name'})\n",
    "semmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "semmed = semmed.drop([0], axis=1)\n",
    "semmed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows where subject and object matches generic concepts\n",
    "generic_cui = semmed.CUI.tolist()\n",
    "len(generic_cui)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn3 = dfn2[~dfn2['subject_cui'].isin(generic_cui)]\n",
    "dfn3.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn4 = dfn3[~dfn3['object_cui'].isin(generic_cui)]\n",
    "dfn4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#map from UMLS to GO, HPO\n",
    "with open('cui_to_ontology_maps/go_hpo_map_dict.pickle', 'rb') as filep:\n",
    "    go_hpo_mapping_dict = pickle.load(filep)\n",
    "len(go_hpo_mapping_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def umls_go_hpo_map(row, col):\n",
    "    if col == 'subject':\n",
    "        cui = row['subject_cui']\n",
    "    elif col == 'object':\n",
    "        cui = row['object_cui']\n",
    "    else:\n",
    "        print('specify if subject or object mapping required')\n",
    "        exit(0)\n",
    "    if cui in go_hpo_mapping_dict:\n",
    "        if len(go_hpo_mapping_dict):\n",
    "            return go_hpo_mapping_dict[cui][0]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn4['subject_obo'] = dfn4.apply(umls_go_hpo_map, axis=1, col='subject')\n",
    "dfn4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn4['object_obo'] = dfn4.apply(umls_go_hpo_map, axis=1, col='object')\n",
    "dfn4.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn4 = dfn4.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn4.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_subset = dfn4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmapped_cui = []\n",
    "unmapped_string_umls = []\n",
    "for i in range(len(dfn_subset.index)):\n",
    "    if not dfn_subset.at[i, 'subject_obo']:\n",
    "        subcui = dfn_subset.at[i, 'subject_cui']\n",
    "        if subcui not in unmapped_cui:\n",
    "            unmapped_cui.append(dfn_subset.at[i, 'subject_cui'])\n",
    "            unmapped_string_umls.append(dfn_subset.at[i, 'subject_name'])\n",
    "    if not dfn_subset.at[i, 'object_obo']:\n",
    "        objcui = dfn_subset.at[i, 'object_cui']\n",
    "        if objcui not in unmapped_cui:\n",
    "            unmapped_cui.append(dfn_subset.at[i, 'object_cui'])\n",
    "            unmapped_string_umls.append(dfn_subset.at[i, 'object_name'])\n",
    "print(len(unmapped_cui), len(unmapped_string_umls))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/predication_files/semrep/unmapped_semrep_subset.txt', 'w') as fileo:\n",
    "    for item in unmapped_string_umls:\n",
    "        fileo.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../resources/predication_files/semrep/unmapped_semrep_cui_subset.txt', 'w') as fileco:\n",
    "    for item in unmapped_cui:\n",
    "        fileco.write(item+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obomap = pd.read_csv('../resources/predication_files/semrep/unmapped_semrep_subset.csv')\n",
    "obomap.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obomap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unmapped_cui_new = []\n",
    "for item in unmapped_cui:\n",
    "    cui = item.strip()\n",
    "    if cui != '':\n",
    "        unmapped_cui_new.append(cui)\n",
    "len(unmapped_cui_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obomap['CUI'] = unmapped_cui_new\n",
    "obomap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obomap = obomap.fillna('')\n",
    "obomap.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_CURIE(row):\n",
    "    curie = row['CURIE']\n",
    "    if curie == '':\n",
    "        return curie\n",
    "    elif 'napdi' in curie:\n",
    "        return curie\n",
    "    elif 'SYNONYM' in curie:\n",
    "        temp = curie.split('_')[0]\n",
    "        temp = temp.replace(':', '_')\n",
    "        return temp\n",
    "    else:\n",
    "        temp = curie.replace(':', '_')\n",
    "        return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obomap['CURIE_new'] = obomap.apply(process_CURIE, axis=1)\n",
    "obomap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obosub = obosub.reset_index(drop=True)\n",
    "obosub.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obosub.to_csv('cui_to_ontology_maps/mapped_semrep_subset.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##create mapping dictionary\n",
    "obomap_dict = {}\n",
    "for i in range(len(obosub.index)):\n",
    "    cui = obosub.at[i, 'CUI']\n",
    "    curie = obosub.at[i, 'CURIE_new']\n",
    "    obomap_dict[cui] = curie\n",
    "len(obomap_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cui_to_ontology_maps/CUItoOBO_20220505.pickle', 'wb') as filep:\n",
    "    pickle.dump(obomap_dict, filep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_obo_mapping(row, col):\n",
    "    if col == 'subject':\n",
    "        cui = row['subject_cui']\n",
    "    elif col == 'object':\n",
    "        cui = row['object_cui']\n",
    "    else:\n",
    "        print('specify if subject or object mapping required')\n",
    "        exit(0)\n",
    "    if cui in obomap_dict:\n",
    "        return obomap_dict[cui]\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPPING\n",
    "dfn_subset['subject_obo'] = dfn_subset.apply(get_obo_mapping, axis=1, col='subject')\n",
    "dfn_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_subset['object_obo'] = dfn_subset.apply(get_obo_mapping, axis=1, col='object')\n",
    "dfn_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_subset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##add labels for all subjects and objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_subset.to_csv('../resources/predication_files/semrep/semrep_all_predications_mapped.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##read file after mapping\n",
    "dfn_subset = pd.read_csv('../resources/predication_files/semrep/semrep_all_predications_mapped.csv')\n",
    "dfn_subset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(row, col):\n",
    "    obo_prefix = 'http://purl.obolibrary.org/obo/'\n",
    "    napdi_prefix = 'http://napdi.org/'\n",
    "    if col == 'predicate':\n",
    "        predicate_obo = row['predicate_obo']\n",
    "        if isinstance(predicate_obo, str):\n",
    "            return obo_prefix+predicate_obo\n",
    "        else:\n",
    "            return ''\n",
    "            \n",
    "    elif col == 'subject':\n",
    "        \n",
    "        subject_obo = row['subject_obo']\n",
    "        if isinstance(subject_obo, str):\n",
    "            if subject_obo == None:\n",
    "                return ''\n",
    "            if 'napdi' in subject_obo:\n",
    "                return napdi_prefix+subject_obo\n",
    "            else:\n",
    "                return obo_prefix+subject_obo\n",
    "        else:\n",
    "            return ''\n",
    "    elif col == 'object':\n",
    "        object_obo = row['object_obo']\n",
    "        if isinstance(object_obo, str):\n",
    "            if object_obo == None:\n",
    "                return ''\n",
    "            if 'napdi' in object_obo:\n",
    "                return napdi_prefix+object_obo\n",
    "            else:\n",
    "                return obo_prefix+object_obo\n",
    "        else:\n",
    "            return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add OBO identifiers to the OBO mappings (where not present) - see df\n",
    "#drop rows with no mappings\n",
    "dfn_subset['subject_obo'] = dfn_subset.apply(add_prefix, axis=1, col='subject')\n",
    "dfn_subset['object_obo'] = dfn_subset.apply(add_prefix, axis=1, col='object')\n",
    "dfn_subset['predicate_obo'] = dfn_subset.apply(add_prefix, axis=1, col='predicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfn_subset.to_csv('../resources/predication_files/semrep/semrep_all_predications_mapped_with_prefix.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = dfn_subset[dfn_subset['subject_obo'] != '']\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new['object_obo'] != '']\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new['predicate_obo'] != '']\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop_duplicates()\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop(['subject_map', 'object_map'], axis=1)\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('../resources/predication_files/semrep/semrep_predications_mapped_only.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create networkx graph from triples\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import networkx as nx  # type: ignore\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from collections import Counter  # type: ignore\n",
    "from more_itertools import unique_everseen  # type: ignore\n",
    "from rdflib import BNode, Graph, Literal, Namespace, URIRef  # type: ignore\n",
    "from rdflib.namespace import OWL, RDF, RDFS  # type: ignore\n",
    "from rdflib.plugins.serializers.nt import _quoteLiteral  # type: ignore\n",
    "import subprocess\n",
    "\n",
    "from tqdm import tqdm  # type: ignore\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "# set-up environment variables\n",
    "obo = Namespace('http://purl.obolibrary.org/obo/')\n",
    "oboinowl = Namespace('http://www.geneontology.org/formats/oboInOwl#')\n",
    "schema = Namespace('http://www.w3.org/2001/XMLSchema#')\n",
    "napdi = Namespace('http://napdi.org/napdi_srs_imports:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = df_new[['subject_obo', 'predicate_obo', 'object_obo']]\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = dfres.drop_duplicates()\n",
    "dfres.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rdflib graph from dataframe triples and serialize as ntriples file\n",
    "graph  = Graph()\n",
    "pred_label = URIRef(\"http://www.w3.org/2000/01/rdf-schema#label\")\n",
    "for i in range(len(df_new.index)):\n",
    "    subj = df_new.at[i, 'subject_obo']\n",
    "    obj = df_new.at[i, 'object_obo']\n",
    "    pred = df_new.at[i, 'predicate_obo']\n",
    "    subj_node = URIRef(subj)\n",
    "    obj_node = URIRef(obj)\n",
    "    predicate = URIRef(pred)\n",
    "    subj_name = df_new.at[i, 'subject_name']\n",
    "    obj_name = df_new.at[i, 'object_name']\n",
    "    graph.add((subj_node, predicate, obj_node))\n",
    "    graph.add((subj_node, pred_label, Literal(subj_name)))\n",
    "    graph.add((obj_node, pred_label, Literal(obj_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.serialize('output_graphs/machineread_semrep.nt', format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n3(node: Union[URIRef, BNode, Literal]) -> str:\n",
    "    \"\"\"Method takes an RDFLib node of type BNode, URIRef, or Literal and serializes it to meet the RDF 1.1 NTriples\n",
    "    format.\n",
    "    Src: https://github.com/RDFLib/rdflib/blob/c11f7b503b50b7c3cdeec0f36261fa09b0615380/rdflib/plugins/serializers/nt.py\n",
    "    Args:\n",
    "        node: An RDFLib\n",
    "    Returns:\n",
    "        serialized_node: A string containing the serialized\n",
    "    \"\"\"\n",
    "    if isinstance(node, Literal): serialized_node = \"%s\" % _quoteLiteral(node)\n",
    "    else: serialized_node = \"%s\" % node.n3()\n",
    "    return serialized_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert rdflib graph to multidigraph - code borrowed from PheKnowLator: kg_utils.py\n",
    "#use the pred key to also create a dictionary with metadata about the edge - \n",
    "#pub_year, pmid, source graph, belief\n",
    "nx_mdg = nx.MultiDiGraph()\n",
    "for s, p, o in tqdm(graph):\n",
    "    #do not save label predicate to gpickle\n",
    "    subj = str(s)\n",
    "    obj = str(o)\n",
    "    pred = str(p)\n",
    "    if pred == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "        continue\n",
    "    else:\n",
    "\n",
    "        pred_key = hashlib.md5('{}{}{}'.format(n3(s), n3(p), n3(o)).encode()).hexdigest()\n",
    "        pmid = str(df_new.loc[(df_new['subject_obo'] == subj) & (df_new['object_obo'] == obj)  & \n",
    "                       (df_new['predicate_obo'] == pred)]['pmid'].values[0])\n",
    "        timestamp = str(df_new.loc[(df_new['subject_obo'] == subj) & (df_new['object_obo'] == obj)  & \n",
    "                                   (df_new['predicate_obo'] == pred)]['year'].values[0])\n",
    "        belief_score = 0.8\n",
    "        nx_mdg.add_node(s, key=n3(s))\n",
    "        nx_mdg.add_node(o, key=n3(o))\n",
    "        nx_mdg.add_edge(s, o, **{'key': p, 'predicate_key': pred_key, 'weight':0.0,\n",
    "                                 'pmid': pmid, 'timestamp': timestamp, 'source_graph': 'machine_read',\n",
    "                                'belief': belief_score})\n",
    "nx.write_gpickle(nx_mdg, \"output_graphs/machineread_semrep.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = len(graph)\n",
    "nodes = len(set(list(graph.subjects()) + list(graph.objects())))\n",
    "rels = len(set(list(graph.predicates())))\n",
    "print(triples, nodes, rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should have less edges than rdflib graph after removing 'labels'\n",
    "nodes = nx.number_of_nodes(nx_mdg)\n",
    "edges = nx.number_of_edges(nx_mdg)\n",
    "density = nx.density(nx_mdg)\n",
    "avg_deg = float(edges)/nodes\n",
    "print(nodes, edges, density, avg_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save node labels as dictionary\n",
    "#key: URI, value is label\n",
    "label_dict = {}\n",
    "for i in range(len(df_new.index)):\n",
    "    subj = str(df_new.at[i, 'subject_obo'])\n",
    "    obj = str(df_new.at[i, 'object_obo'])\n",
    "    pred = str(df_new.at[i, 'predicate_obo'])\n",
    "    if subj not in label_dict:\n",
    "        label_dict[subj] = {}\n",
    "        label_dict[subj]['entity_type'] = 'NODES'\n",
    "        label_dict[subj]['label'] = df_new.at[i, 'subject_name']\n",
    "        label_dict[subj]['cui'] = df_new.at[i, 'subject_cui']\n",
    "    if obj not in label_dict:\n",
    "        label_dict[obj] = {}\n",
    "        label_dict[obj]['entity_type'] = 'NODES'\n",
    "        label_dict[obj]['label'] = df_new.at[i, 'object_name']\n",
    "        label_dict[obj]['cui'] = df_new.at[i, 'object_cui']\n",
    "    if pred not in label_dict:\n",
    "        label_dict[pred] = {}\n",
    "        label_dict[pred]['entity_type'] = 'RELATIONS'\n",
    "        label_dict[pred]['label'] = df_new.at[i, 'predicate']\n",
    "len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('output_graphs/machineread_semrep_NodeLabels.pickle', 'wb') as file_p:\n",
    "    pickle.dump(label_dict, file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = pd.DataFrame.from_dict(label_dict, orient='index')\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = dfmap.reset_index()\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = dfmap.rename(columns={\"index\":\"entity_uri\"})\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap.to_csv('output_graphs/machineread_semrep_NodeLabels.tsv', index=False, sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##run closure in separate notebook - see machine_read_closure.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
