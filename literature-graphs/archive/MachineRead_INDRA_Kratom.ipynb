{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4ed225-3c78-4018-ad58-07782a9775f3",
   "metadata": {},
   "source": [
    "## Create literature-based graph for kratom from INDRA/REACH triples\n",
    "\n",
    "### Steps for processing:\n",
    "1. Map subjects, objects, and relations to OBO ontologies.\n",
    "2. Add prefixes for all CURIEs.\n",
    "3. Save triples as NetworkX graph.\n",
    "4. Save triples as ntriples graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe53642d-fb2f-419c-b87a-3ead4161f666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "import numpy as np\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "honest-bloom",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgt = pd.read_csv('../resources/predication_files/kratom_all_predicates_INDRA.tsv', sep='\\t')\n",
    "dfgt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "primary-guidance",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfgt.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "center-bankruptcy",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-dryer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixes reach mappings to OBO (if available) and adds text if no mapping or blank name of entity\n",
    "for i in range(len(df.index)):\n",
    "    subj_ground = df.at[i, 'subj_reach_grounding']\n",
    "    obj_ground = df.at[i, 'obj_reach_grounding']\n",
    "    subj_map = df.at[i, 'subj_map_reach']\n",
    "    obj_map = df.at[i, 'obj_map_reach']\n",
    "    if subj_ground == '(None, None)' or subj_ground == np.nan:\n",
    "        temp = subj_map.split(',')\n",
    "        if 'GO' in subj_map or 'CHEBI' in subj_map:\n",
    "            for item in temp:\n",
    "                if 'GO' in item or 'CHEBI' in item:\n",
    "                    df.at[i, 'subj_reach_grounding'] = item\n",
    "        elif 'UP' in subj_map:\n",
    "            for item in temp:\n",
    "                if 'UP' in item:\n",
    "                    df.at[i, 'subj_reach_grounding'] = item\n",
    "        elif 'TEXT' in subj_map:\n",
    "            if df.at[i, 'subject_source'] == '':\n",
    "                for item in temp:\n",
    "                    if 'TEXT' in item:\n",
    "                        df.at[i, 'subject_source'] = item.split(':')[-1]\n",
    "    elif 'GO' not in subj_ground and 'CHEBI' not in subj_ground and 'UP' not in subj_ground:\n",
    "        temp = subj_map.split(',')\n",
    "        if 'GO' in subj_map or 'CHEBI' in subj_map:\n",
    "            for item in temp:\n",
    "                if 'GO' in item or 'CHEBI' in item:\n",
    "                    df.at[i, 'subj_reach_grounding'] = item\n",
    "        elif 'UP' in subj_map:\n",
    "            for item in temp:\n",
    "                if 'UP' in item:\n",
    "                    df.at[i, 'subj_reach_grounding'] = item\n",
    "        elif 'TEXT' in subj_map:\n",
    "            if df.at[i, 'subject_source'] == '':\n",
    "                for item in temp:\n",
    "                    if 'TEXT' in item:\n",
    "                        df.at[i, 'subject_source'] = item.split(':')[-1]\n",
    "    \n",
    "    #same for object mapping\n",
    "    if obj_ground == '(None, None)' or obj_ground == np.nan:\n",
    "        temp = obj_map.split(',')\n",
    "        if 'GO' in obj_map or 'CHEBI' in obj_map:\n",
    "            for item in temp:\n",
    "                if 'GO' in item or 'CHEBI' in item:\n",
    "                    df.at[i, 'obj_reach_grounding'] = item\n",
    "        elif 'UP' in obj_map:\n",
    "            for item in temp:\n",
    "                if 'UP' in item:\n",
    "                    df.at[i, 'obj_reach_grounding'] = item\n",
    "        elif 'TEXT' in obj_map:\n",
    "            if df.at[i, 'object_source'] == '':\n",
    "                for item in temp:\n",
    "                    if 'TEXT' in item:\n",
    "                        df.at[i, 'object_source'] = item.split(':')[-1]\n",
    "    elif 'GO' not in obj_ground and 'CHEBI' not in obj_ground and 'UP' not in obj_ground:\n",
    "        temp = obj_map.split(',')\n",
    "        if 'GO' in obj_map or 'CHEBI' in obj_map:\n",
    "            for item in temp:\n",
    "                if 'GO' in item or 'CHEBI' in item:\n",
    "                    df.at[i, 'obj_reach_grounding'] = item\n",
    "        elif 'UP' in obj_map:\n",
    "            for item in temp:\n",
    "                if 'UP' in item:\n",
    "                    df.at[i, 'obj_reach_grounding'] = item\n",
    "        elif 'TEXT' in obj_map:\n",
    "            if df.at[i, 'object_source'] == '':\n",
    "                for item in temp:\n",
    "                    if 'TEXT' in item:\n",
    "                        df.at[i, 'object_source'] = item.split(':')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-jenny",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['subject_cui', 'subject_name', 'subject_source', 'predicate', 'object_source',\n",
    "       'object_cui', 'object_name', 'subj_reach_grounding', 'obj_reach_grounding', 'pmid', \n",
    "           'year', 'belief', 'sentence']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "promotional-algeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicate_obo'] = None\n",
    "df['subject_obo'] = None\n",
    "df['object_obo'] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "starting-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cui_to_ontology_maps/go_hpo_map_dict.pickle', 'rb') as filep:\n",
    "    go_hpo_mapping_dict = pickle.load(filep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "suburban-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.fillna('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fossil-watch",
   "metadata": {},
   "outputs": [],
   "source": [
    "#map cui to reach grounding\n",
    "reach_grounding_dict = {}\n",
    "for i in range(len(df.index)):\n",
    "    sub_cui = df.at[i, 'subject_cui']\n",
    "    sub_source = df.at[i, 'subject_source']\n",
    "    obj_cui = df.at[i, 'object_cui']\n",
    "    obj_source = df.at[i, 'object_source']\n",
    "    sub_ground = df.at[i, 'subj_reach_grounding']\n",
    "    obj_ground = df.at[i, 'obj_reach_grounding']\n",
    "    sub_key = i\n",
    "    obj_key = i\n",
    "    if sub_cui != '':\n",
    "        sub_key = sub_cui\n",
    "    elif sub_source != '':\n",
    "        sub_key = sub_source\n",
    "    if obj_cui != '':\n",
    "        obj_key = obj_cui\n",
    "    elif obj_source != '':\n",
    "        obj_key = obj_source\n",
    "    if sub_key not in reach_grounding_dict:\n",
    "        reach_grounding_dict[sub_key] = []\n",
    "    if obj_key not in reach_grounding_dict:\n",
    "        reach_grounding_dict[obj_key] = []\n",
    "    if sub_ground != np.nan:\n",
    "        if 'CHEBI' in sub_ground or 'GO' in sub_ground:\n",
    "            subject_map = sub_ground.split(\"'\")[-2]\n",
    "            subject_map = subject_map.replace(':', '_')\n",
    "            reach_grounding_dict[sub_key].append(subject_map)\n",
    "        elif 'UP' in sub_ground:\n",
    "            subject_map = sub_ground.split(\"'\")[-2]\n",
    "            subject_map = 'PR_' + subject_map\n",
    "            reach_grounding_dict[sub_key].append(subject_map)\n",
    "    if obj_ground != np.nan:\n",
    "        if 'CHEBI' in obj_ground or 'GO' in obj_ground:\n",
    "            object_map = obj_ground.split(\"'\")[-2]\n",
    "            object_map = object_map.replace(':', '_')\n",
    "            reach_grounding_dict[obj_key].append(object_map)\n",
    "        elif 'UP' in obj_ground:\n",
    "            object_map = obj_ground.split(\"'\")[-2]\n",
    "            object_map = 'PR_' + object_map\n",
    "            reach_grounding_dict[obj_key].append(object_map)\n",
    "print(len(reach_grounding_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intimate-weekly",
   "metadata": {},
   "outputs": [],
   "source": [
    "predMapD = {\n",
    "    'regulateactivity':'RO_0011002',\n",
    "    'regulateamount':'RO_0011003',\n",
    "    'phosphorylation':'RO_0002447',\n",
    "    'dephosphorylation':'GO_0006470',\n",
    "    'ubiquitination':'RO_0002480',\n",
    "    'deubiquitination':'GO_0016579',\n",
    "    'sumoylation':'RO_0002436',\n",
    "    'desumoylation':'RO_0002436',\n",
    "    'hydroxylation':'GO_0018126',\n",
    "    'dehydroxylation':'RO_0002436',\n",
    "    'acetylation':'GO_0006473',\n",
    "    'deacetylation':'GO_0006476',\n",
    "    'glycosylation':'GO_0006486',\n",
    "    'deglycosylation':'GO_0006517',\n",
    "    'farnesylation':'RO_0002436',\n",
    "    'defarnesylation':'RO_0002436',\n",
    "    'geranylgeranylation':'RO_0002436',\n",
    "    'degeranylgeranylation':'RO_0002436',\n",
    "    'palmitoylation':'RO_0002436',\n",
    "    'depalmitoylation':'RO_0002436',\n",
    "    'myristoylation':'RO_0002436',\n",
    "    'demyristoylation':'RO_0002436',\n",
    "    'ribosylation':'RO_0002436',\n",
    "    'deribosylation':'RO_0002436',\n",
    "    'methylation':'GO_0006479',\n",
    "    'demethylation':'GO_0006482',\n",
    "    'activation':'RO_0002448',\n",
    "    'inhibition':'RO_0002449',\n",
    "    'increaseamount':'RO_0011009',\n",
    "    'decreaseamount':'RO_0011010'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "coordinate-brand",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if reach_grounding has multiple values, currently only first one is taken -- assess if this is the best option\n",
    "def get_obo_mapping(row, col):\n",
    "    if col == 'subject':\n",
    "        cui = row['subject_cui']\n",
    "        source = row['subject_source']\n",
    "    elif col == 'object':\n",
    "        cui = row['object_cui']\n",
    "        source = row['object_source']\n",
    "    else:\n",
    "        print('specify is subject or object mapping required')\n",
    "        exit(0)\n",
    "    if cui in go_hpo_mapping_dict:\n",
    "        if len(go_hpo_mapping_dict):\n",
    "            return go_hpo_mapping_dict[cui][0]\n",
    "    if cui in reach_grounding_dict:\n",
    "        if len(reach_grounding_dict[cui]):\n",
    "            return reach_grounding_dict[cui][0]\n",
    "    if source in reach_grounding_dict:\n",
    "        if len(reach_grounding_dict[source]):\n",
    "            return reach_grounding_dict[source][0]\n",
    "    return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-billion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relation_mapping(row):\n",
    "    rel = row['predicate'].lower()\n",
    "    if rel in predMapD:\n",
    "        return predMapD[rel]\n",
    "    else:\n",
    "        return ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "collaborative-cricket",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['predicate_obo'] = df.apply(relation_mapping, axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "formal-oxygen",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAPPING\n",
    "df['subject_obo'] = df.apply(get_obo_mapping, axis=1, col='subject')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-opportunity",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['object_obo'] = df.apply(get_obo_mapping, axis=1, col='object')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd10d989-1c61-4d2a-bc04-e94f969c8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('cui_to_ontology_maps/CUItoOBO_20220505.pickle', 'rb') as filep:\n",
    "    onto_dict = pickle.load(filep)\n",
    "len(onto_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13af968-e4ca-499f-9fcb-06ce0d3024ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get ontorunner mappings and add to df\n",
    "def get_obo_onto_mapping(row, col):\n",
    "    if col == 'subject':\n",
    "        cui = row['subject_cui']\n",
    "        mapping = row['subject_obo']\n",
    "    elif col == 'object':\n",
    "        cui = row['object_cui']\n",
    "        mapping = row['object_obo']\n",
    "    else:\n",
    "        print('specify if subject or object mapping required')\n",
    "        exit(0)\n",
    "    if mapping == '':\n",
    "        if cui in onto_dict:\n",
    "            return onto_dict[cui]\n",
    "    else:\n",
    "        return mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b52e2696-8903-411c-9795-55c4cc1a2e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['subject_obo'] = df.apply(get_obo_onto_mapping, axis=1, col='subject')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10e736b9-a504-4d01-84b8-e37aab07b60f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['object_obo'] = df.apply(get_obo_onto_mapping, axis=1, col='object')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitting-possession",
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop rows with [] mapping\n",
    "df = df.loc[df['subject_obo'] != '[]']\n",
    "df = df.loc[df['object_obo'] != '[]']\n",
    "df = df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "peaceful-intent",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_prefix(row, col):\n",
    "    obo_prefix = 'http://purl.obolibrary.org/obo/'\n",
    "    if col == 'predicate':\n",
    "        predicate_obo = row['predicate_obo']\n",
    "        return obo_prefix+predicate_obo\n",
    "    elif col == 'subject':\n",
    "        subject_obo = row['subject_obo']\n",
    "        if isinstance(subject_obo, list) and subject_obo:\n",
    "            subject_obo = subject_obo[0]\n",
    "        if subject_obo == None:\n",
    "            return ''\n",
    "        subject_obo = subject_obo.replace(']', '')\n",
    "        subject_obo = subject_obo.replace('[', '')\n",
    "        subject_obo = subject_obo.replace(')', '')\n",
    "        subject_obo = subject_obo.replace('(', '')\n",
    "        if 'http' not in subject_obo:\n",
    "            return obo_prefix+subject_obo\n",
    "        else:\n",
    "            return subject_obo\n",
    "    elif col == 'object':\n",
    "        object_obo = row['object_obo']\n",
    "        if isinstance(object_obo, list) and object_obo:\n",
    "            object_obo = object_obo[0]\n",
    "        if object_obo == None:\n",
    "            return ''\n",
    "        object_obo = object_obo.replace(']', '')\n",
    "        object_obo = object_obo.replace('[', '')\n",
    "        object_obo = object_obo.replace(')', '')\n",
    "        object_obo = object_obo.replace('(', '')\n",
    "        if 'http' not in object_obo:\n",
    "            return obo_prefix+object_obo\n",
    "        else:\n",
    "            return object_obo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-criterion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#add OBO identifiers to the OBO mappings (where not present) - see df\n",
    "#drop rows with no mappings\n",
    "df['subject_obo'] = df.apply(add_prefix, axis=1, col='subject')\n",
    "df['object_obo'] = df.apply(add_prefix, axis=1, col='object')\n",
    "df['predicate_obo'] = df.apply(add_prefix, axis=1, col='predicate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc747a43-1938-4f1e-ad09-96d5add5070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "##fix napdi identifiers\n",
    "for i in range(len(df.index)):\n",
    "    subj = df.at[i, 'subject_obo']\n",
    "    obj = df.at[i, 'object_obo']\n",
    "    if 'napdi' in subj:\n",
    "        subjnew = subj.replace('http://purl.obolibrary.org/obo/', 'http://napdi.org/')\n",
    "        df.at[i, 'subject_obo'] = subjnew\n",
    "    if 'napdi' in obj:\n",
    "        objnew = obj.replace('http://purl.obolibrary.org/obo/', 'http://napdi.org/')\n",
    "        df.at[i, 'object_obo'] = objnew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numerous-olive",
   "metadata": {},
   "outputs": [],
   "source": [
    "obo_prefix = 'http://purl.obolibrary.org/obo/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "searching-divorce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove all rows with blank obo mappings and only prefix rows\n",
    "df_new = df[df['subject_obo'] != '']\n",
    "df_new = df_new[df_new['subject_obo'] != obo_prefix]\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tribal-member",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new[df_new['object_obo'] != '']\n",
    "df_new = df_new[df_new['object_obo'] != obo_prefix]\n",
    "df_new.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "covered-quantum",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.drop_duplicates()\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "narrative-pierce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new.to_csv('../resources/predication_files/kratom_all_predicates_INDRA_processed.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dramatic-association",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new = df_new.reset_index(drop=True)\n",
    "df_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-jacksonville",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create networkx graph from triples\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import networkx as nx  # type: ignore\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from collections import Counter  # type: ignore\n",
    "from more_itertools import unique_everseen  # type: ignore\n",
    "from rdflib import BNode, Graph, Literal, Namespace, URIRef  # type: ignore\n",
    "from rdflib.namespace import OWL, RDF, RDFS  # type: ignore\n",
    "from rdflib.plugins.serializers.nt import _quoteLiteral  # type: ignore\n",
    "import subprocess\n",
    "\n",
    "from tqdm import tqdm  # type: ignore\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union\n",
    "\n",
    "# set-up environment variables\n",
    "obo = Namespace('http://purl.obolibrary.org/obo/')\n",
    "oboinowl = Namespace('http://www.geneontology.org/formats/oboInOwl#')\n",
    "schema = Namespace('http://www.w3.org/2001/XMLSchema#')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eight-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres = df_new[['subject_obo', 'predicate_obo', 'object_obo']]\n",
    "dfres.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sustainable-league",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfres.to_csv('../resources/predication_files/kratom_all_predicates_INDRA_processed_triples.tsv', sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legitimate-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create rdflib graph from dataframe triples and serialize as ntriples file\n",
    "graph  = Graph()\n",
    "pred_label = URIRef(\"http://www.w3.org/2000/01/rdf-schema#label\")\n",
    "for i in range(len(df_new.index)):\n",
    "    subj = df_new.at[i, 'subject_obo']\n",
    "    obj = df_new.at[i, 'object_obo']\n",
    "    pred = df_new.at[i, 'predicate_obo']\n",
    "    subj_node = URIRef(subj)\n",
    "    obj_node = URIRef(obj)\n",
    "    predicate = URIRef(pred)\n",
    "    subj_name = df_new.at[i, 'subject_name']\n",
    "    obj_name = df_new.at[i, 'object_name']\n",
    "    graph.add((subj_node, predicate, obj_node))\n",
    "    graph.add((subj_node, pred_label, Literal(subj_name)))\n",
    "    graph.add((obj_node, pred_label, Literal(obj_name)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-candidate",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.serialize('output_graphs/machineread_kratom_INDRA.nt', format='nt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fitted-gambling",
   "metadata": {},
   "outputs": [],
   "source": [
    "def n3(node: Union[URIRef, BNode, Literal]) -> str:\n",
    "    \"\"\"Method takes an RDFLib node of type BNode, URIRef, or Literal and serializes it to meet the RDF 1.1 NTriples\n",
    "    format.\n",
    "    Src: https://github.com/RDFLib/rdflib/blob/c11f7b503b50b7c3cdeec0f36261fa09b0615380/rdflib/plugins/serializers/nt.py\n",
    "    Args:\n",
    "        node: An RDFLib\n",
    "    Returns:\n",
    "        serialized_node: A string containing the serialized\n",
    "    \"\"\"\n",
    "    if isinstance(node, Literal): serialized_node = \"%s\" % _quoteLiteral(node)\n",
    "    else: serialized_node = \"%s\" % node.n3()\n",
    "    return serialized_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "historical-parts",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert rdflib graph to multidigraph - code borrowed from PheKnowLator: kg_utils.py\n",
    "#use the pred key to also create a dictionary with metadata about the edge - \n",
    "#pub_year, pmid, source graph, belief\n",
    "nx_mdg = nx.MultiDiGraph()\n",
    "for s, p, o in tqdm(graph):\n",
    "    #do not save label predicate to gpickle\n",
    "    subj = str(s)\n",
    "    obj = str(o)\n",
    "    pred = str(p)\n",
    "    if pred == 'http://www.w3.org/2000/01/rdf-schema#label':\n",
    "        continue\n",
    "    else:\n",
    "\n",
    "        pred_key = hashlib.md5('{}{}{}'.format(n3(s), n3(p), n3(o)).encode()).hexdigest()\n",
    "        pmid = str(df_new.loc[(df_new['subject_obo'] == subj) & (df_new['object_obo'] == obj)  & \n",
    "                       (df_new['predicate_obo'] == pred)]['pmid'].values[0])\n",
    "        timestamp = str(df_new.loc[(df_new['subject_obo'] == subj) & (df_new['object_obo'] == obj)  & \n",
    "                                   (df_new['predicate_obo'] == pred)]['year'].values[0])\n",
    "        belief_score = df_new.loc[(df_new['subject_obo'] == subj) & (df_new['object_obo'] == obj)  & \n",
    "                                   (df_new['predicate_obo'] == pred)]['belief'].values[0]\n",
    "        nx_mdg.add_node(s, key=n3(s))\n",
    "        nx_mdg.add_node(o, key=n3(o))\n",
    "        nx_mdg.add_edge(s, o, **{'key': p, 'predicate_key': pred_key, 'weight':0.0,\n",
    "                                 'pmid': pmid, 'timestamp': timestamp, 'source_graph': 'machine_read',\n",
    "                                'belief': belief_score})\n",
    "nx.write_gpickle(nx_mdg, \"output_graphs/machineread_kratom_INDRA.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "saved-definition",
   "metadata": {},
   "outputs": [],
   "source": [
    "triples = len(graph)\n",
    "nodes = len(set(list(graph.subjects()) + list(graph.objects())))\n",
    "rels = len(set(list(graph.predicates())))\n",
    "print(triples, nodes, rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should have less edges than rdflib graph after removing 'labels'\n",
    "nodes = nx.number_of_nodes(nx_mdg)\n",
    "edges = nx.number_of_edges(nx_mdg)\n",
    "density = nx.density(nx_mdg)\n",
    "avg_deg = float(edges)/nodes\n",
    "print(nodes, edges, density, avg_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "respected-capture",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save node labels as dictionary\n",
    "#key: URI, value is label\n",
    "label_dict = {}\n",
    "for i in range(len(df_new.index)):\n",
    "    subj = str(df_new.at[i, 'subject_obo'])\n",
    "    obj = str(df_new.at[i, 'object_obo'])\n",
    "    pred = str(df_new.at[i, 'predicate_obo'])\n",
    "    if subj not in label_dict:\n",
    "        label_dict[subj] = {}\n",
    "        label_dict[subj]['entity_type'] = 'NODES'\n",
    "        label_dict[subj]['label'] = df_new.at[i, 'subject_name']\n",
    "        label_dict[subj]['cui'] = df_new.at[i, 'subject_cui']\n",
    "    if obj not in label_dict:\n",
    "        label_dict[obj] = {}\n",
    "        label_dict[obj]['entity_type'] = 'NODES'\n",
    "        label_dict[obj]['label'] = df_new.at[i, 'object_name']\n",
    "        label_dict[obj]['cui'] = df_new.at[i, 'object_cui']\n",
    "    if pred not in label_dict:\n",
    "        label_dict[pred] = {}\n",
    "        label_dict[pred]['entity_type'] = 'RELATIONS'\n",
    "        label_dict[pred]['label'] = df_new.at[i, 'predicate']\n",
    "len(label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dominican-portuguese",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output_graphs/machineread_kratom_INDRA_NodeLabels.pickle', 'wb') as file_p:\n",
    "    pickle.dump(label_dict, file_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inside-stock",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = pd.DataFrame.from_dict(label_dict, orient='index')\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outstanding-finger",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = dfmap.reset_index()\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smart-circular",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap = dfmap.rename(columns={\"index\":\"entity_uri\"})\n",
    "dfmap.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "printable-differential",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfmap.to_csv('output_graphs/machineread_kratom_INDRA_NodeLabels.tsv', index=False, sep='\\t')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
