{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NaPDI machine reading knowledge graph instance closure\n",
    "\n",
    "Closure run for SemRep and REACH predications in merged machine reading graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set up the CLIPS environment\n",
    "import clips\n",
    "env = clips.Environment()\n",
    "\n",
    "MIN_PREDICATION_BELIEF = 0\n",
    "MIN_TRANSITIVE_BELIEF = 0  # chosen because it retains most depth 1 transitive inferences over semmed  \n",
    "\n",
    "## NOTE: BE SURE TO CLEAR test-inference.ntriples EACH TIME BEFORE RUNNING!!\n",
    "## This accomplishes that\n",
    "f = open(\"closure_output/test-inference.ntriples\",'w')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load merged machine reading graph - ntriples/gpickle - already mapped and processed - LOAD TSVs instead\n",
    "##load TSVs after mapping for all machine reading output\n",
    "mr_reach_gt = '../resources/predication_files/greentea_all_predicates_INDRA_processed.tsv'\n",
    "mr_reach_kt = '../resources/predication_files/kratom_all_predicates_INDRA_processed.tsv'\n",
    "mr_semrep = '../resources/predication_files/semrep/semrep_predications_mapped_only.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgt = pd.read_csv(mr_reach_gt, sep='\\t')\n",
    "dfgt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkt = pd.read_csv(mr_reach_kt, sep='\\t')\n",
    "dfkt.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsem = pd.read_csv(mr_semrep)\n",
    "dfsem.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgt = dfgt[['pmid', 'subject_cui', 'subject_name', 'object_cui', 'object_name', 'pub_year', 'predicate', 'sentence', 'predicate_obo', 'subject_obo', 'object_obo', 'belief']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfkt = dfkt[['pmid', 'subject_cui', 'subject_name', 'object_cui', 'object_name', 'year', 'predicate', 'sentence', 'predicate_obo', 'subject_obo', 'object_obo', 'belief']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfsem = dfsem[['pmid', 'subject_cui', 'subject_name', 'object_cui',  'object_name', 'year', 'predicate', 'source_text', 'predicate_obo', 'subject_obo', 'object_obo']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##all dataframes should have the same columns\n",
    "#add belief = 0.8 to semrep predications\n",
    "dfsem['belief'] = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfgt = dfgt.rename({'pub_year':'year'}, axis=1)\n",
    "dfsem = dfsem.rename({'source_text':'sentence'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([dfgt, dfkt, dfsem])\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.reset_index(drop=True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example\n",
    "##Transitive predicates - part of, precedes, stimulates/positively regulates\n",
    "##Symmetric predicates - interacts_with, moleculary_interacts_with\n",
    "env.clear()\n",
    "env.reset()\n",
    "\n",
    "env.eval('(open \"closure_output/test-inference.ntriples\" writeFile \"a\")')\n",
    "\n",
    "env.build(\"\"\"\n",
    "(deftemplate oav\n",
    " (slot object)\n",
    " (slot attribute)\n",
    " (slot value)\n",
    " (slot predNS)\n",
    " (slot inferred (default No))\n",
    " (slot belief (default 0.0)))\n",
    "\"\"\")\n",
    "\n",
    "## Transitive rule \n",
    "env.build(\"\"\"\n",
    "(defrule transitive\n",
    "  \"a simple transitivity rule\"\n",
    "  (oav (object ?o)\n",
    "       (attribute ?pred&:(member$ ?pred (create$ http://purl.obolibrary.org/obo/BFO_0000063 http://purl.obolibrary.org/obo/BFO_0000050 http://purl.obolibrary.org/obo/RO_0002213)))\n",
    "       (value ?s)\n",
    "       (predNS RO)\n",
    "       (inferred No)\n",
    "       (belief ?b1))\n",
    "  (oav (object ?s)\n",
    "       (attribute ?pred)\n",
    "       (value ?q)\n",
    "       (predNS RO)\n",
    "       (inferred No)\n",
    "       (belief ?b2))\n",
    "   (test (>= (* ?b1 ?b2) {}))\n",
    "  =>\n",
    "  (assert (oav (object ?o)\n",
    "               (attribute ?pred)\n",
    "               (value ?q)\n",
    "               (inferred Yes)\n",
    "               (predNS RO)\n",
    "               (belief (* ?b1 ?b2))))\n",
    "  \n",
    "  (printout writeFile (format nil \"<%s><%s><%s>.%n\" ?o ?pred ?q))   \n",
    ")\n",
    "\"\"\".format(MIN_TRANSITIVE_BELIEF))\n",
    "# NOTE: add this line to RHS to see the belief scores:\n",
    "# (printout writeFile (format nil \"b1: %f, b2: %f, belief: %f>.%n\" ?b1 ?b2 (* ?b1 ?b2))) \n",
    "\n",
    "## simplerule for symmetric relationships \n",
    "env.build(\"\"\"\n",
    "(defrule symmetric\n",
    "  \"a simple symmetry rule\"\n",
    "  (oav (object ?o)\n",
    "       (attribute ?pred&:(member$ ?pred (create$ http://purl.obolibrary.org/obo/RO_0002434 http://purl.obolibrary.org/obo/RO_0002436)))\n",
    "       (value ?s)\n",
    "       (predNS RO)\n",
    "       (inferred No)\n",
    "       (belief ?b))\n",
    "  =>\n",
    "  (assert (oav (object ?s)\n",
    "               (attribute ?pred)\n",
    "               (value ?o)\n",
    "               (inferred Yes)\n",
    "               (predNS RO)\n",
    "               (belief ?b)))\n",
    "  \n",
    "  (printout writeFile (format nil \"<%s><%s><%s>.%n\" ?o ?pred ?s))  \n",
    ")\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predMapD = {\n",
    "    'regulateactivity':'RO_0011002',\n",
    "    'regulateamount':'RO_0011003',\n",
    "    'phosphorylation':'RO_0002447',\n",
    "    'dephosphorylation':'GO_0006470',\n",
    "    'ubiquitination':'RO_0002480',\n",
    "    'deubiquitination':'GO_0016579',\n",
    "    'sumoylation':'RO_0002436',\n",
    "    'desumoylation':'RO_0002436',\n",
    "    'hydroxylation':'GO_0018126',\n",
    "    'dehydroxylation':'RO_0002436',\n",
    "    'acetylation':'GO_0006473',\n",
    "    'deacetylation':'GO_0006476',\n",
    "    'glycosylation':'GO_0006486',\n",
    "    'deglycosylation':'GO_0006517',\n",
    "    'farnesylation':'RO_0002436',\n",
    "    'defarnesylation':'RO_0002436',\n",
    "    'geranylgeranylation':'RO_0002436',\n",
    "    'degeranylgeranylation':'RO_0002436',\n",
    "    'palmitoylation':'RO_0002436',\n",
    "    'depalmitoylation':'RO_0002436',\n",
    "    'myristoylation':'RO_0002436',\n",
    "    'demyristoylation':'RO_0002436',\n",
    "    'ribosylation':'RO_0002436',\n",
    "    'deribosylation':'RO_0002436',\n",
    "    'methylation':'GO_0006479',\n",
    "    'demethylation':'GO_0006482',\n",
    "    'activation':'RO_0002448',\n",
    "    'inhibition':'RO_0002449',\n",
    "    'increaseamount':'RO_0011009',\n",
    "    'decreaseamount':'RO_0011010',\n",
    "    'affects': 'RO_0002596',\n",
    "    'associated_with': 'RO_0002610',\n",
    "    'augments': 'RO_0002598',\n",
    "    'causes': 'RO_0002566',\n",
    "    'coexists_with': 'RO_0002490',\n",
    "    'complicates': 'RO_0003309',\n",
    "    'disrupts': 'RO_0002212',\n",
    "    'inhibits': 'RO_0002449',\n",
    "    'interacts_with': 'RO_0002434',\n",
    "    'part_of': 'BFO_0000050',\n",
    "    'precedes': 'BFO_0000063',\n",
    "    'predisposes': 'RO_0003302',\n",
    "    'prevents': 'RO_0002599',\n",
    "    'produces': 'RO_0003000',\n",
    "    'stimulates': 'RO_0002213',\n",
    "    'treats': 'RO_0002606'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Facts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "originalTriplesF = open('closure_output/original-triples.ntriples','w')\n",
    "\n",
    "resourceD = {}\n",
    "resourceDinv = {}\n",
    "rcnt = 0\n",
    "fctStrD = {}\n",
    "#semTypeD = {}\n",
    "labelsD = {}\n",
    "\n",
    "for i in range(len(df.index)): \n",
    "   \n",
    "    belief = df.at[i, 'belief']\n",
    "    if belief < MIN_PREDICATION_BELIEF:\n",
    "        continue\n",
    "    \n",
    "    (subj_obo, pred_obo, obj_obo) = (df.at[i, 'subject_obo'],\n",
    "                                    df.at[i, 'predicate_obo'],\n",
    "                                    df.at[i, 'object_obo'])\n",
    "    (subj, pred, obj) = (df.at[i,'subject_name'],\n",
    "                        df.at[i,'predicate'].lower().strip(),\n",
    "                        df.at[i, 'object_name'])\n",
    "\n",
    "    # only write out and/or do inference over some predicates\n",
    "    if pred not in predMapD:        \n",
    "        continue\n",
    "        \n",
    "    # write the original triple to file, regardless of the predicate\n",
    "    originalTriplesF.write(\"<{}><{}><{}>.\\n\".format(subj_obo,pred_obo,obj_obo))\n",
    "        \n",
    "    # Track the subject and object names\n",
    "    subjName = subj\n",
    "    objName = obj\n",
    "        \n",
    "    if not resourceD.get(subj_obo):\n",
    "        resourceD[subj_obo] = 'r{}'.format(rcnt)\n",
    "        resourceDinv['r{}'.format(rcnt)] = subj_obo\n",
    "        rcnt += 1\n",
    "    \n",
    "    if not resourceD.get(obj_obo):\n",
    "        resourceD[obj_obo] = 'r{}'.format(rcnt)\n",
    "        resourceDinv['r{}'.format(rcnt)] = obj_obo\n",
    "        rcnt += 1    \n",
    "    \n",
    "        \n",
    "    fctStr = \"\"\"\n",
    "(oav (object {})\n",
    "     (attribute {})\n",
    "     (value {})\n",
    "     (predNS {})\n",
    "     (belief {})\n",
    ")\"\"\".format(resourceD[subj_obo], pred_obo, resourceD[obj_obo], 'RO', belief)\n",
    "    \n",
    "    if not fctStrD.get(fctStr): \n",
    "        env.assert_string(fctStr)\n",
    "        fctStrD[fctStr] = 1\n",
    "    \n",
    "    \n",
    "    # write the human readable labels as triples\n",
    "    if isinstance(subj,str):\n",
    "        originalTriplesF.write('<{}><http://www.w3.org/2000/01/rdf-schema#label> \"{}\".\\n'.format(subj_obo,subj.replace('\"','')))\n",
    "    if isinstance(obj,str):\n",
    "        originalTriplesF.write('<{}><http://www.w3.org/2000/01/rdf-schema#label> \"{}\".\\n'.format(obj_obo,obj.replace('\"','')))\n",
    "\n",
    "originalTriplesF.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for fact in env.facts():\n",
    "    print(fact)\n",
    "    if i == 20:\n",
    "        break\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.run()\n",
    "# count of inferences by cutoff for transitive belief score: 0.65 = 2241, 0 = 14539"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output tells use how many RHS made changes to working memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "f = open('closure_output/test-inference.ntriples','r')\n",
    "buf = f.read()\n",
    "f.close()\n",
    "rsL = buf.split('\\n')\n",
    "\n",
    "'''rgx = re.compile('(http://purl.obolibrary.org/obo/)([A-Z_0-9]+)')\n",
    "for i in range(0,len(rsL)):\n",
    "    if rsL[i] == \"\":\n",
    "        continue\n",
    "        \n",
    "    ml = rgx.findall(rsL[i])\n",
    "    if len(ml) != 1:\n",
    "        print('ERROR: could not match on predicate regex: {}'.format(rsL[i]))\n",
    "        continue\n",
    "        \n",
    "    (uri,predicate) = ml[0]\n",
    "    rsL[i] = rsL[i].replace(predicate, predMapD[predicate])'''\n",
    "    \n",
    "\n",
    "f = open('closure_output/inferred-transitive-and-symmetric.ntriples','w')\n",
    "rgx = re.compile('(r[0-9]+)')\n",
    "for it in rsL:\n",
    "    keyL = rgx.findall(it)\n",
    "    newTr = it\n",
    "    for k in keyL:\n",
    "        if resourceDinv.get(k):\n",
    "            newTr = newTr.replace(k, resourceDinv[k])            \n",
    "        else:\n",
    "            print('ERROR: key not found in resourceDinv: {}'.format(k))\n",
    "    f.write(newTr + '\\n')\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save as gpickle file with metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from rdflib.namespace import OWL, RDF, RDFS\n",
    "import os\n",
    "import pickle, json\n",
    "\n",
    "#Create networkx graph from triples\n",
    "import glob\n",
    "import hashlib\n",
    "import json\n",
    "import networkx as nx  # type: ignore\n",
    "import os\n",
    "import os.path\n",
    "\n",
    "from collections import Counter  # type: ignore\n",
    "from more_itertools import unique_everseen  # type: ignore\n",
    "from rdflib import BNode, Graph, Literal, Namespace, URIRef  # type: ignore\n",
    "from rdflib.namespace import OWL, RDF, RDFS  # type: ignore\n",
    "from rdflib.plugins.serializers.nt import _quoteLiteral  # type: ignore\n",
    "import subprocess\n",
    "\n",
    "from tqdm import tqdm  # type: ignore\n",
    "from typing import Dict, List, Optional, Set, Tuple, Union"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('closure_output/inferred-transitive-and-symmetric.ntriples','r') as file1:\n",
    "    g = file1.read()\n",
    "graph1 = g.split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obo = Namespace('http://purl.obolibrary.org/obo/')\n",
    "oboinowl = Namespace('http://www.geneontology.org/formats/oboInOwl#')\n",
    "schema = Namespace('http://www.w3.org/2001/XMLSchema#')\n",
    "napdi = Namespace('http://napdi.org/napdi_srs_imports:')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n3(node: Union[URIRef, BNode, Literal]) -> str:\n",
    "    \"\"\"Method takes an RDFLib node of type BNode, URIRef, or Literal and serializes it to meet the RDF 1.1 NTriples\n",
    "    format.\n",
    "    Src: https://github.com/RDFLib/rdflib/blob/c11f7b503b50b7c3cdeec0f36261fa09b0615380/rdflib/plugins/serializers/nt.py\n",
    "    Args:\n",
    "        node: An RDFLib\n",
    "    Returns:\n",
    "        serialized_node: A string containing the serialized\n",
    "    \"\"\"\n",
    "    if isinstance(node, Literal): serialized_node = \"%s\" % _quoteLiteral(node)\n",
    "    else: serialized_node = \"%s\" % node.n3()\n",
    "    return serialized_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert rdflib graph to multidigraph - code borrowed from PheKnowLator: kg_utils.py\n",
    "#use the pred key to also create a dictionary with metadata about the edge - add INF tag for inferred triples\n",
    "errors = []\n",
    "nx_mdg = nx.MultiDiGraph()\n",
    "for triple in graph1:\n",
    "    #do not save label predicate to gpickle\n",
    "\n",
    "    rgx = re.compile('(http://[a-zA-Z0-9/._:]+)')\n",
    "    match = rgx.findall(triple)\n",
    "    if len(match)!=3:\n",
    "        errors.append(triple)\n",
    "        continue\n",
    "    subj = match[0]\n",
    "    obj = match[2]\n",
    "    pred = match[1]\n",
    "    s = URIRef(subj)\n",
    "    p = URIRef(pred)\n",
    "    o = URIRef(obj)\n",
    "\n",
    "    pred_key = hashlib.md5('{}{}{}'.format(n3(s), n3(p), n3(o)).encode()).hexdigest()\n",
    "    nx_mdg.add_node(s, key=n3(s))\n",
    "    nx_mdg.add_node(o, key=n3(o))\n",
    "    nx_mdg.add_edge(s, o, **{'key': p, 'predicate_key': pred_key, 'weight':0.0,\n",
    "                             'source_graph': 'machine_read_INF'})\n",
    "\n",
    "nx.write_gpickle(nx_mdg, \"closure_output/machineread_inferred_symmetric_transitive.gpickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should have less edges than rdflib graph after removing 'labels'\n",
    "nodes = nx.number_of_nodes(nx_mdg)\n",
    "edges = nx.number_of_edges(nx_mdg)\n",
    "density = nx.density(nx_mdg)\n",
    "avg_deg = float(edges)/nodes\n",
    "print(nodes, edges, density, avg_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##get stats of inferred triples\n",
    "with open('closure_output/inferred-transitive-and-symmetric.ntriples') as filei:\n",
    "    g = filei.read()\n",
    "graph1 = g.split('\\n')\n",
    "len(graph1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = []\n",
    "p = []\n",
    "o = []\n",
    "for triple in graph1:\n",
    "    rgx = re.compile('(http://[a-zA-Z0-9/._:]+)')\n",
    "    match = rgx.findall(triple)\n",
    "    if len(match)!=3:\n",
    "        errors.append(triple)\n",
    "        continue\n",
    "    subj = match[0]\n",
    "    obj = match[2]\n",
    "    pred = match[1]\n",
    "    s.append(subj)\n",
    "    p.append(pred)\n",
    "    o.append(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinf = pd.DataFrame()\n",
    "dfinf['subject_obo'] = s\n",
    "dfinf['pred_obo'] = p\n",
    "dfinf['object_obo'] = o\n",
    "dfinf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinf.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfinf['pred_obo'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
